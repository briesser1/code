
# Performance Measure Specification: Field Reference & Data Model

## Purpose

This document defines the recommended fields for cataloging and operationalizing organizational performance measures. The structure draws from three traditions:

1. **Healthcare quality measurement** — HQMF metadata, CQL logic patterns, and eCQM population structures
2. **Balanced Scorecard / KPI management** — strategic alignment, ownership, targets, and reporting cadence
3. **Data governance** — data element lineage, source documentation, and stewardship

The goal is a system that is more rigorous than a spreadsheet tracker but less prescriptive than full CQL/HQMF specification — a "practical specification" layer that supports 34+ organizational measures with room to grow.

---

## Data Model Overview

The model has three core entities:

```
┌─────────────────────┐
│     MEASURE          │  (1)
│  (core specification)│
└─────────┬───────────┘
          │ 1:many
          ▼
┌─────────────────────┐
│   DATA ELEMENT       │  (many)
│ (inputs to the calc) │
└─────────────────────┘

┌─────────────────────┐
│  MEASURE RESULT LOG  │  (many per measure, over time)
│ (periodic scores)    │
└─────────────────────┘
```

A single **Measure** has many **Data Elements** (the inputs needed to compute it) and accumulates many **Measure Results** over time (the periodic scores/values).

---

## Entity 1: Measure (Core Specification)

### Identity & Classification

| Field | Type | Description | Example Values |
|---|---|---|---|
| `measure_id` | text (unique) | Org-assigned identifier | `ORG-PM-001` |
| `measure_title` | text | Full descriptive name | "Timely Completion of Annual Case Reviews" |
| `measure_short_name` | text | Abbreviated name for dashboards | "Case Review Timeliness" |
| `measure_version` | text | Version of the specification | `1.0`, `2.1` |
| `measure_status` | enum | Lifecycle status | `draft`, `pilot`, `active`, `under_review`, `retired` |
| `effective_date` | date | Date specification becomes active | 2026-01-01 |
| `retirement_date` | date (nullable) | Date measure is/was retired | null |

### Strategic Alignment

| Field | Type | Description | Example Values |
|---|---|---|---|
| `strategic_domain` | text | High-level category or BSC perspective | "Service Quality", "Workforce", "Financial Stewardship", "Compliance" |
| `strategic_objective` | text | The organizational goal this measure supports | "Improve timeliness of services to families" |
| `measure_type` | enum | What the measure captures | `outcome`, `process`, `structure`, `balancing` |
| `priority_level` | enum | Organizational priority tier | `critical`, `important`, `monitoring` |

### Scoring & Directionality

| Field | Type | Description | Example Values |
|---|---|---|---|
| `scoring_type` | enum | How the result is computed | `proportion`, `ratio`, `continuous_variable`, `cohort`, `composite` |
| `desired_direction` | enum | Which way is "better" | `increase`, `decrease`, `target_range` |
| `unit_of_measure` | text | Unit for the result value | "percent", "days", "count", "rate per 1000" |

**Scoring type definitions** (adapted from eCQM conventions):

- **Proportion** — numerator / denominator where numerator ⊆ denominator (e.g., % of cases reviewed on time)
- **Ratio** — numerator / denominator where numerator is NOT necessarily a subset of the denominator (e.g., staff-to-client ratio)
- **Continuous variable** — a calculation over a population that produces a value like a mean, median, or aggregate (e.g., average days to close a case)
- **Cohort** — identifies a group meeting certain criteria without computing a rate (e.g., list of clients eligible for a program)
- **Composite** — a weighted or combined score from multiple sub-measures

### Population Definitions

These fields define *who or what* is being measured. For proportion and ratio measures, this maps directly to the eCQM population model. For non-proportion measures, use whichever fields apply.

| Field | Type | Description |
|---|---|---|
| `target_population` | text | Plain-language description of the universe being measured |
| `initial_population` | text | The broadest group from which the measure draws — equivalent to the "starting universe" |
| `denominator` | text | The subset of the initial population eligible for the measure (for proportion/ratio) |
| `denominator_exclusions` | text (nullable) | Cases removed from the denominator for clinical, administrative, or policy reasons |
| `denominator_exceptions` | text (nullable) | Cases with acceptable reasons for not meeting numerator criteria |
| `numerator` | text | The subset of the denominator that meets the desired condition |
| `numerator_exclusions` | text (nullable) | Cases to remove from the numerator count |

> **Tip:** Even for continuous variable measures, defining an "initial population" and "measure population" in plain language helps clarify scope. You don't need to force every measure into a strict numerator/denominator frame.

### Calculation Logic

This is the "CQL-lite" section — enough rigor to be unambiguous but written in structured natural language rather than formal CQL.

| Field | Type | Description |
|---|---|---|
| `calculation_narrative` | long text | Plain-language step-by-step description of how to compute the measure from raw data. Should be precise enough that two analysts would produce the same result independently. |
| `calculation_formula` | text | Compact formula representation (optional but recommended) |
| `aggregation_method` | enum | How individual observations roll up | 
| `risk_adjustment` | text (nullable) | Description of any risk adjustment or stratification applied |

**`aggregation_method` values:** `count`, `sum`, `mean`, `median`, `proportion`, `weighted_average`, `min`, `max`, `percentile`

**Example `calculation_narrative`:**

> **Step 1:** Identify all cases assigned to the organization that were open at any point during the measurement period.
> 
> **Step 2 (Denominator):** From Step 1, include only cases where an annual review was due during the measurement period. A review is "due" if the most recent completed review is ≥ 335 days prior to the end of the measurement period, OR the case was opened ≥ 335 days ago and has never had a review.
> 
> **Step 3 (Denominator Exclusions):** Exclude cases transferred out of the organization before their review due date.
> 
> **Step 4 (Numerator):** From the denominator, count cases where the annual review was completed within 30 days of the due date.
> 
> **Result:** Numerator / Denominator, expressed as a percentage.

**Example `calculation_formula`:**

```
(Count of cases with timely review) / (Count of cases with review due) × 100
```

### Targets & Benchmarks

| Field | Type | Description | Example Values |
|---|---|---|---|
| `target_value` | numeric | The performance target | 95.0 |
| `target_type` | enum | How to interpret the target | `minimum_threshold`, `stretch_goal`, `benchmark`, `regulatory_requirement` |
| `baseline_value` | numeric (nullable) | Starting performance when measure was established | 78.5 |
| `baseline_period` | text (nullable) | Time period for baseline | "FY2025 Q1" |
| `benchmark_value` | numeric (nullable) | External or peer benchmark | 90.0 |
| `benchmark_source` | text (nullable) | Where the benchmark comes from | "National average per XYZ report, 2025" |
| `performance_threshold_red` | numeric (nullable) | Below this = critical concern | 70.0 |
| `performance_threshold_yellow` | numeric (nullable) | Below this = caution | 85.0 |

### Reporting Configuration

| Field | Type | Description | Example Values |
|---|---|---|---|
| `measurement_period_type` | enum | Cadence of data collection | `monthly`, `quarterly`, `semi_annual`, `annual`, `rolling_12_month` |
| `measurement_period_duration` | text | How long each measurement window is | "Calendar quarter", "Rolling 12 months" |
| `reporting_frequency` | enum | How often results are reported | `monthly`, `quarterly`, `annual` |
| `reporting_lag_days` | integer | Expected delay between period end and data availability | 45 |
| `reporting_audience` | text | Who receives the results | "Board of Directors, Program Leadership" |

### Stewardship & Governance

| Field | Type | Description | Example Values |
|---|---|---|---|
| `measure_owner` | text | Person accountable for the measure's performance | "Director of Quality" |
| `measure_developer` | text | Person/team who specified the measure | "Analytics Team" |
| `data_steward` | text | Person responsible for data quality | "Data Analyst, Research Dept" |
| `approved_by` | text (nullable) | Who approved the specification | "Quality Committee" |
| `approved_date` | date (nullable) | When it was approved | 2026-01-15 |
| `next_review_date` | date | When the spec is next due for review | 2027-01-15 |
| `change_log` | long text | History of specification changes | "v1.0 - Initial. v1.1 - Revised exclusion criteria per committee feedback." |

### Contextual Metadata

| Field | Type | Description | Example Values |
|---|---|---|---|
| `measure_description` | long text | Brief narrative description of what the measure captures and why it matters | |
| `measure_rationale` | long text | Why this measure was chosen — the business or policy case | |
| `measure_guidance` | long text (nullable) | Implementation notes, known edge cases, analyst tips | |
| `references` | text (nullable) | Citations to regulations, standards, or literature | "45 CFR 1355.44(b)(2)" |
| `related_measures` | text (nullable) | IDs of measures that are related or should be interpreted together | "ORG-PM-003, ORG-PM-017" |
| `stratifications` | text (nullable) | Dimensions by which the measure should be broken out | "Region, program type, worker caseload tier" |

---

## Entity 2: Data Element (One-to-Many with Measure)

Each measure depends on one or more data elements. This table captures what data is needed, where it comes from, and how it maps into the calculation.

| Field | Type | Description | Example Values |
|---|---|---|---|
| `data_element_id` | text (unique) | Element identifier | `DE-042` |
| `measure_id` | text (FK) | Which measure uses this element | `ORG-PM-001` |
| `element_name` | text | Human-readable name | "Case Review Completion Date" |
| `element_description` | text | What this data element represents | "The date the annual case review was completed and signed by the supervisor" |
| `data_type` | enum | Type of value | `date`, `datetime`, `integer`, `decimal`, `boolean`, `text`, `coded_value` |
| `value_set` | text (nullable) | If coded, the valid values | "Pending, Complete, Waived" |
| `data_source_system` | text | System of record | "Case Management System (CMS)", "HRIS", "Financial System" |
| `data_source_table_or_field` | text (nullable) | Specific table/field if known | "tbl_reviews.completion_date" |
| `collection_method` | enum | How data enters the system | `automated_extract`, `manual_entry`, `calculated`, `imported` |
| `data_quality_notes` | text (nullable) | Known quality issues or caveats | "Completion date is sometimes backdated; validate against supervisor sign-off timestamp" |
| `role_in_calculation` | enum | How this element is used | `population_filter`, `numerator_criteria`, `denominator_criteria`, `exclusion_criteria`, `measured_value`, `stratifier`, `risk_adjuster` |
| `required` | boolean | Is this element essential or supplemental | true |
| `responsible_party` | text (nullable) | Who is responsible for data entry or extraction | "Case workers via CMS" |

---

## Entity 3: Measure Result Log (Optional, for tracking over time)

If you want the system to also hold periodic results (moving beyond pure specification into a scorecard), consider this companion table.

| Field | Type | Description | Example Values |
|---|---|---|---|
| `result_id` | auto-increment | Unique result record | 1042 |
| `measure_id` | text (FK) | Which measure | `ORG-PM-001` |
| `measurement_period` | text | The period this result covers | "2026-Q1" |
| `period_start_date` | date | Start of measurement window | 2026-01-01 |
| `period_end_date` | date | End of measurement window | 2026-03-31 |
| `numerator_value` | numeric (nullable) | Numerator count | 187 |
| `denominator_value` | numeric (nullable) | Denominator count | 205 |
| `result_value` | numeric | Computed measure result | 91.2 |
| `performance_status` | enum | RAG status relative to targets | `green`, `yellow`, `red`, `not_applicable` |
| `stratification_key` | text (nullable) | If stratified, which subgroup | "Region: East" |
| `data_completeness_pct` | numeric (nullable) | % of expected data that was available | 98.5 |
| `analyst_notes` | long text (nullable) | Contextual notes for this period | "Spike due to backlog clearance from prior quarter" |
| `reported_date` | date | When result was finalized | 2026-05-15 |
| `reported_by` | text | Who produced the result | "J. Smith" |

---

## Enumeration Reference

For quick implementation, here are the controlled vocabularies referenced above:

| Field | Valid Values |
|---|---|
| `measure_status` | `draft`, `pilot`, `active`, `under_review`, `retired` |
| `measure_type` | `outcome`, `process`, `structure`, `balancing` |
| `scoring_type` | `proportion`, `ratio`, `continuous_variable`, `cohort`, `composite` |
| `desired_direction` | `increase`, `decrease`, `target_range` |
| `target_type` | `minimum_threshold`, `stretch_goal`, `benchmark`, `regulatory_requirement` |
| `measurement_period_type` | `monthly`, `quarterly`, `semi_annual`, `annual`, `rolling_12_month` |
| `reporting_frequency` | `monthly`, `quarterly`, `semi_annual`, `annual` |
| `aggregation_method` | `count`, `sum`, `mean`, `median`, `proportion`, `weighted_average`, `min`, `max`, `percentile` |
| `data_type` (element) | `date`, `datetime`, `integer`, `decimal`, `boolean`, `text`, `coded_value` |
| `collection_method` | `automated_extract`, `manual_entry`, `calculated`, `imported` |
| `role_in_calculation` | `population_filter`, `numerator_criteria`, `denominator_criteria`, `exclusion_criteria`, `measured_value`, `stratifier`, `risk_adjuster` |
| `performance_status` | `green`, `yellow`, `red`, `not_applicable` |
| `priority_level` | `critical`, `important`, `monitoring` |

---

## Research Notes: How Organizations Track Measures

### Common Approaches (from Spreadsheet to System)

**Level 1 — Spreadsheet tracker.** This is where most orgs start. A single workbook with one row per measure, columns for key attributes, and a separate tab for periodic results. Simple but fragile: no relational integrity, version control is manual, and it becomes unwieldy past ~20 measures.

**Level 2 — Structured database or platform.** Organizations move to tools like Monday.com, Smartsheet, Airtable, or a custom Access/SQL database. The key upgrade is relational linking (measures → data elements → results) and controlled vocabularies via dropdowns. This is the sweet spot for 20-50 measures.

**Level 3 — Dedicated performance management software.** Tools like ClearPoint Strategy, Balanced Scorecard software, or custom dashboards in Power BI/Tableau. These add automated data ingestion, RAG status calculation, trend visualization, and role-based reporting. Best for organizations with dedicated analytics staff.

**Level 4 — Full specification systems.** The eCQM world lives here — HQMF/CQL/FHIR-based specifications that are machine-executable. Overkill for organizational measures but the metadata patterns (measure identity, populations, logic separation) are universally useful.

### Key Principles from the Research

1. **Separate specification from results.** The definition of *what* to measure should live independently from the *values* over time. This lets you version the spec without losing historical data.

2. **Document calculation logic at the "two analyst" standard.** If two people can independently compute the same result from the same data using your narrative, the spec is good enough.

3. **Track data lineage.** Knowing which system, table, and field feed each measure prevents the "nobody knows where this number comes from" problem when staff turn over.

4. **Build in governance fields from day one.** Ownership, review dates, and change logs seem like overhead until the 18th month when someone asks "why did this number change methodology?"

5. **Use the eCQM population model even for non-clinical measures.** The initial population → denominator → numerator → exclusions pattern is remarkably versatile for any rate-based measure.

---

## Snowflake Implementation

This section provides a complete implementation of the performance measure management system in Snowflake, including schema design, DDL, loading patterns, and analytical views.

### Architecture Overview

```
┌─────────────────────────────────────────────────────────┐
│                   SNOWFLAKE ACCOUNT                      │
│                                                          │
│  ┌─────────────────────────────────────────────────┐    │
│  │  DB: PERFORMANCE_MEASURES                        │    │
│  │                                                   │    │
│  │  SCHEMA: SPECIFICATION   (measure definitions)    │    │
│  │    ├─ MEASURE                                     │    │
│  │    ├─ DATA_ELEMENT                                │    │
│  │    ├─ MEASURE_CHANGE_LOG                          │    │
│  │    └─ MEASURE_RELATIONSHIP                        │    │
│  │                                                   │    │
│  │  SCHEMA: RESULTS         (periodic scores)        │    │
│  │    ├─ MEASURE_RESULT                              │    │
│  │    └─ MEASURE_RESULT_STRATIFIED                   │    │
│  │                                                   │    │
│  │  SCHEMA: REFERENCE       (controlled vocabs)      │    │
│  │    ├─ LU_MEASURE_STATUS                           │    │
│  │    ├─ LU_SCORING_TYPE                             │    │
│  │    ├─ LU_MEASURE_TYPE                             │    │
│  │    └─ ... (other lookups)                         │    │
│  │                                                   │    │
│  │  SCHEMA: ANALYTICS       (views & reporting)      │    │
│  │    ├─ VW_MEASURE_SCORECARD                        │    │
│  │    ├─ VW_MEASURE_TREND                            │    │
│  │    └─ VW_DATA_LINEAGE                             │    │
│  └─────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────┘
```

**Why separate schemas?** Specifications change infrequently and need tight governance. Results flow in on a cadence and grow continuously. Separating them lets you apply different access controls, cloning strategies, and Time Travel retention policies to each.

---

### Database & Schema Setup

```sql
-- =============================================================
-- DATABASE AND SCHEMA CREATION
-- =============================================================

CREATE DATABASE IF NOT EXISTS PERFORMANCE_MEASURES
    DATA_RETENTION_TIME_IN_DAYS = 90
    COMMENT = 'Organizational performance measure specifications, results, and analytics';

USE DATABASE PERFORMANCE_MEASURES;

CREATE SCHEMA IF NOT EXISTS SPECIFICATION
    COMMENT = 'Measure definitions, data elements, and governance metadata';

CREATE SCHEMA IF NOT EXISTS RESULTS
    COMMENT = 'Periodic measure scores and stratified breakdowns';

CREATE SCHEMA IF NOT EXISTS REFERENCE
    COMMENT = 'Controlled vocabularies and lookup tables';

CREATE SCHEMA IF NOT EXISTS ANALYTICS
    COMMENT = 'Reporting views and materialized summaries';
```

---

### Reference / Lookup Tables

These enforce the controlled vocabularies from the Enumeration Reference section. Using lookup tables rather than bare CHECK constraints gives you descriptive labels for reporting and makes it easy to add values without DDL changes.

```sql
USE SCHEMA REFERENCE;

-- =============================================================
-- LOOKUP TABLES (controlled vocabularies)
-- =============================================================

CREATE OR REPLACE TABLE LU_MEASURE_STATUS (
    status_code       VARCHAR(20)   PRIMARY KEY,
    status_label      VARCHAR(100)  NOT NULL,
    sort_order        INT,
    is_active         BOOLEAN       DEFAULT TRUE,
    description       VARCHAR(500)
);

INSERT INTO LU_MEASURE_STATUS (status_code, status_label, sort_order, description) VALUES
    ('draft',        'Draft',        1, 'Specification is being developed'),
    ('pilot',        'Pilot',        2, 'Measure is in trial/testing phase'),
    ('active',       'Active',       3, 'Measure is in production use'),
    ('under_review', 'Under Review', 4, 'Specification is being revised'),
    ('retired',      'Retired',      5, 'Measure is no longer in use');

CREATE OR REPLACE TABLE LU_SCORING_TYPE (
    scoring_code      VARCHAR(30)   PRIMARY KEY,
    scoring_label     VARCHAR(100)  NOT NULL,
    description       VARCHAR(500),
    has_numerator     BOOLEAN       DEFAULT TRUE,
    has_denominator   BOOLEAN       DEFAULT TRUE
);

INSERT INTO LU_SCORING_TYPE (scoring_code, scoring_label, description, has_numerator, has_denominator) VALUES
    ('proportion',         'Proportion',         'Numerator is a subset of the denominator',                    TRUE,  TRUE),
    ('ratio',              'Ratio',              'Numerator and denominator are independent populations',        TRUE,  TRUE),
    ('continuous_variable','Continuous Variable', 'Aggregated value (mean, median, etc.) over a population',     FALSE, FALSE),
    ('cohort',             'Cohort',             'Identifies a group meeting criteria without computing a rate', FALSE, FALSE),
    ('composite',          'Composite',          'Weighted or combined score from multiple sub-measures',        FALSE, FALSE);

CREATE OR REPLACE TABLE LU_MEASURE_TYPE (
    type_code         VARCHAR(20)   PRIMARY KEY,
    type_label        VARCHAR(100)  NOT NULL,
    description       VARCHAR(500)
);

INSERT INTO LU_MEASURE_TYPE VALUES
    ('outcome',    'Outcome',    'Measures the end result or impact'),
    ('process',    'Process',    'Measures whether a step or activity was performed'),
    ('structure',  'Structure',  'Measures organizational capacity, resources, or systems'),
    ('balancing',  'Balancing',  'Monitors for unintended consequences of improvement efforts');

CREATE OR REPLACE TABLE LU_DESIRED_DIRECTION (
    direction_code    VARCHAR(20)   PRIMARY KEY,
    direction_label   VARCHAR(100)  NOT NULL
);

INSERT INTO LU_DESIRED_DIRECTION VALUES
    ('increase',     'Higher is Better'),
    ('decrease',     'Lower is Better'),
    ('target_range', 'Within Target Range');

CREATE OR REPLACE TABLE LU_PRIORITY_LEVEL (
    priority_code     VARCHAR(20)   PRIMARY KEY,
    priority_label    VARCHAR(100)  NOT NULL,
    sort_order        INT
);

INSERT INTO LU_PRIORITY_LEVEL VALUES
    ('critical',   'Critical',   1),
    ('important',  'Important',  2),
    ('monitoring', 'Monitoring', 3);

CREATE OR REPLACE TABLE LU_PERIOD_TYPE (
    period_code       VARCHAR(30)   PRIMARY KEY,
    period_label      VARCHAR(100)  NOT NULL
);

INSERT INTO LU_PERIOD_TYPE VALUES
    ('monthly',          'Monthly'),
    ('quarterly',        'Quarterly'),
    ('semi_annual',      'Semi-Annual'),
    ('annual',           'Annual'),
    ('rolling_12_month', 'Rolling 12-Month');

CREATE OR REPLACE TABLE LU_AGGREGATION_METHOD (
    method_code       VARCHAR(30)   PRIMARY KEY,
    method_label      VARCHAR(100)  NOT NULL
);

INSERT INTO LU_AGGREGATION_METHOD VALUES
    ('count', 'Count'), ('sum', 'Sum'), ('mean', 'Mean'),
    ('median', 'Median'), ('proportion', 'Proportion'),
    ('weighted_average', 'Weighted Average'),
    ('min', 'Minimum'), ('max', 'Maximum'), ('percentile', 'Percentile');

CREATE OR REPLACE TABLE LU_TARGET_TYPE (
    target_code       VARCHAR(30)   PRIMARY KEY,
    target_label      VARCHAR(100)  NOT NULL
);

INSERT INTO LU_TARGET_TYPE VALUES
    ('minimum_threshold',      'Minimum Threshold'),
    ('stretch_goal',           'Stretch Goal'),
    ('benchmark',              'Benchmark'),
    ('regulatory_requirement', 'Regulatory Requirement');

CREATE OR REPLACE TABLE LU_DATA_ELEMENT_TYPE (
    type_code         VARCHAR(20)   PRIMARY KEY,
    type_label        VARCHAR(100)  NOT NULL
);

INSERT INTO LU_DATA_ELEMENT_TYPE VALUES
    ('date', 'Date'), ('datetime', 'Datetime'), ('integer', 'Integer'),
    ('decimal', 'Decimal'), ('boolean', 'Boolean'), ('text', 'Text'),
    ('coded_value', 'Coded Value');

CREATE OR REPLACE TABLE LU_COLLECTION_METHOD (
    method_code       VARCHAR(30)   PRIMARY KEY,
    method_label      VARCHAR(100)  NOT NULL
);

INSERT INTO LU_COLLECTION_METHOD VALUES
    ('automated_extract', 'Automated Extract'),
    ('manual_entry',      'Manual Entry'),
    ('calculated',        'Calculated/Derived'),
    ('imported',          'Imported from External Source');

CREATE OR REPLACE TABLE LU_CALC_ROLE (
    role_code         VARCHAR(30)   PRIMARY KEY,
    role_label        VARCHAR(100)  NOT NULL,
    description       VARCHAR(500)
);

INSERT INTO LU_CALC_ROLE VALUES
    ('population_filter',     'Population Filter',     'Defines the initial population or measure scope'),
    ('numerator_criteria',    'Numerator Criteria',    'Determines if a case meets the desired condition'),
    ('denominator_criteria',  'Denominator Criteria',  'Determines eligibility for the measure'),
    ('exclusion_criteria',    'Exclusion Criteria',    'Removes cases from numerator or denominator'),
    ('measured_value',        'Measured Value',        'The value being aggregated (for continuous variable)'),
    ('stratifier',            'Stratifier',            'Dimension for breaking out results'),
    ('risk_adjuster',         'Risk Adjuster',         'Used in risk adjustment calculations');

CREATE OR REPLACE TABLE LU_PERFORMANCE_STATUS (
    status_code       VARCHAR(20)   PRIMARY KEY,
    status_label      VARCHAR(100)  NOT NULL,
    hex_color         VARCHAR(7)    COMMENT 'For dashboard rendering'
);

INSERT INTO LU_PERFORMANCE_STATUS VALUES
    ('green',          'On Target',       '#28A745'),
    ('yellow',         'Caution',         '#FFC107'),
    ('red',            'Critical',        '#DC3545'),
    ('not_applicable', 'Not Applicable',  '#6C757D');
```

---

### Core Tables: Specification Schema

```sql
USE SCHEMA SPECIFICATION;

-- =============================================================
-- MEASURE (core specification)
-- =============================================================

CREATE OR REPLACE TABLE MEASURE (
    -- Identity & Classification
    measure_id                VARCHAR(30)    PRIMARY KEY,
    measure_title             VARCHAR(500)   NOT NULL,
    measure_short_name        VARCHAR(100),
    measure_version           VARCHAR(20)    DEFAULT '1.0',
    measure_status            VARCHAR(20)    NOT NULL DEFAULT 'draft'
                              REFERENCES REFERENCE.LU_MEASURE_STATUS(status_code),

    effective_date            DATE,
    retirement_date           DATE,

    -- Strategic Alignment
    strategic_domain          VARCHAR(200),
    strategic_objective       VARCHAR(1000),
    measure_type              VARCHAR(20)
                              REFERENCES REFERENCE.LU_MEASURE_TYPE(type_code),
    priority_level            VARCHAR(20)    DEFAULT 'important'
                              REFERENCES REFERENCE.LU_PRIORITY_LEVEL(priority_code),

    -- Scoring & Directionality
    scoring_type              VARCHAR(30)    NOT NULL
                              REFERENCES REFERENCE.LU_SCORING_TYPE(scoring_code),
    desired_direction         VARCHAR(20)
                              REFERENCES REFERENCE.LU_DESIRED_DIRECTION(direction_code),
    unit_of_measure           VARCHAR(50),

    -- Population Definitions
    target_population         VARCHAR(2000),
    initial_population        VARCHAR(4000),
    denominator               VARCHAR(4000),
    denominator_exclusions    VARCHAR(4000),
    denominator_exceptions    VARCHAR(4000),
    numerator                 VARCHAR(4000),
    numerator_exclusions      VARCHAR(4000),

    -- Calculation Logic
    calculation_narrative     VARCHAR(16000) COMMENT 'Step-by-step plain-language logic — the CQL-lite spec',
    calculation_formula       VARCHAR(2000),
    aggregation_method        VARCHAR(30)
                              REFERENCES REFERENCE.LU_AGGREGATION_METHOD(method_code),
    risk_adjustment           VARCHAR(2000),

    -- Targets & Benchmarks
    target_value              NUMBER(12,4),
    target_type               VARCHAR(30)
                              REFERENCES REFERENCE.LU_TARGET_TYPE(target_code),
    baseline_value            NUMBER(12,4),
    baseline_period           VARCHAR(100),
    benchmark_value           NUMBER(12,4),
    benchmark_source          VARCHAR(500),
    performance_threshold_red    NUMBER(12,4),
    performance_threshold_yellow NUMBER(12,4),

    -- Reporting Configuration
    measurement_period_type   VARCHAR(30)
                              REFERENCES REFERENCE.LU_PERIOD_TYPE(period_code),
    measurement_period_duration VARCHAR(200),
    reporting_frequency       VARCHAR(30)
                              REFERENCES REFERENCE.LU_PERIOD_TYPE(period_code),
    reporting_lag_days        INT,
    reporting_audience        VARCHAR(1000),

    -- Stewardship & Governance
    measure_owner             VARCHAR(200),
    measure_developer         VARCHAR(200),
    data_steward              VARCHAR(200),
    approved_by               VARCHAR(200),
    approved_date             DATE,
    next_review_date          DATE,

    -- Contextual Metadata
    measure_description       VARCHAR(4000),
    measure_rationale         VARCHAR(4000),
    measure_guidance          VARCHAR(8000),
    measure_references        VARCHAR(2000),
    stratifications           VARCHAR(2000),

    -- Audit
    created_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),
    created_by                VARCHAR(100)   DEFAULT CURRENT_USER(),
    updated_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),
    updated_by                VARCHAR(100)   DEFAULT CURRENT_USER()
);

-- =============================================================
-- DATA_ELEMENT (one-to-many with MEASURE)
-- =============================================================

CREATE OR REPLACE TABLE DATA_ELEMENT (
    data_element_id           VARCHAR(30)    PRIMARY KEY,
    measure_id                VARCHAR(30)    NOT NULL
                              REFERENCES MEASURE(measure_id),

    element_name              VARCHAR(200)   NOT NULL,
    element_description       VARCHAR(2000),

    data_type                 VARCHAR(20)
                              REFERENCES REFERENCE.LU_DATA_ELEMENT_TYPE(type_code),
    value_set                 VARCHAR(2000)  COMMENT 'Valid coded values, if applicable',

    data_source_system        VARCHAR(200),
    data_source_table_or_field VARCHAR(500),
    collection_method         VARCHAR(30)
                              REFERENCES REFERENCE.LU_COLLECTION_METHOD(method_code),
    data_quality_notes        VARCHAR(2000),

    role_in_calculation       VARCHAR(30)    NOT NULL
                              REFERENCES REFERENCE.LU_CALC_ROLE(role_code),
    is_required               BOOLEAN        DEFAULT TRUE,
    responsible_party         VARCHAR(200),

    -- Audit
    created_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),
    updated_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP()
);

-- =============================================================
-- MEASURE_CHANGE_LOG (append-only history)
-- =============================================================

CREATE OR REPLACE TABLE MEASURE_CHANGE_LOG (
    change_id                 INT            AUTOINCREMENT PRIMARY KEY,
    measure_id                VARCHAR(30)    NOT NULL
                              REFERENCES MEASURE(measure_id),
    change_date               DATE           NOT NULL DEFAULT CURRENT_DATE(),
    changed_by                VARCHAR(100),
    previous_version          VARCHAR(20),
    new_version               VARCHAR(20),
    change_summary            VARCHAR(4000)  NOT NULL,
    change_detail             VARCHAR(16000) COMMENT 'Detailed description of what changed and why',

    created_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP()
);

-- =============================================================
-- MEASURE_RELATIONSHIP (many-to-many: related measures)
-- =============================================================

CREATE OR REPLACE TABLE MEASURE_RELATIONSHIP (
    measure_id_from           VARCHAR(30)    NOT NULL
                              REFERENCES MEASURE(measure_id),
    measure_id_to             VARCHAR(30)    NOT NULL
                              REFERENCES MEASURE(measure_id),
    relationship_type         VARCHAR(50)    NOT NULL
                              COMMENT 'e.g., related, component_of, balancing_for, replaces',
    description               VARCHAR(500),

    PRIMARY KEY (measure_id_from, measure_id_to, relationship_type)
);
```

---

### Core Tables: Results Schema

```sql
USE SCHEMA RESULTS;

-- =============================================================
-- MEASURE_RESULT (periodic scores — one row per measure per period)
-- =============================================================

CREATE OR REPLACE TABLE MEASURE_RESULT (
    result_id                 INT            AUTOINCREMENT PRIMARY KEY,
    measure_id                VARCHAR(30)    NOT NULL
                              REFERENCES SPECIFICATION.MEASURE(measure_id),

    measurement_period        VARCHAR(30)    NOT NULL COMMENT 'e.g., 2026-Q1, 2026-01, FY2026',
    period_start_date         DATE           NOT NULL,
    period_end_date           DATE           NOT NULL,

    numerator_value           NUMBER(12,4),
    denominator_value         NUMBER(12,4),
    result_value              NUMBER(12,4)   NOT NULL,

    performance_status        VARCHAR(20)
                              REFERENCES REFERENCE.LU_PERFORMANCE_STATUS(status_code),

    data_completeness_pct     NUMBER(5,2),
    analyst_notes             VARCHAR(4000),

    reported_date             DATE,
    reported_by               VARCHAR(100),

    -- Audit
    created_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),
    updated_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),

    -- Prevent duplicate results for same measure + period
    UNIQUE (measure_id, measurement_period)
);

-- =============================================================
-- MEASURE_RESULT_STRATIFIED (breakdowns by dimension)
-- =============================================================

CREATE OR REPLACE TABLE MEASURE_RESULT_STRATIFIED (
    strat_result_id           INT            AUTOINCREMENT PRIMARY KEY,
    result_id                 INT            NOT NULL
                              REFERENCES MEASURE_RESULT(result_id),
    measure_id                VARCHAR(30)    NOT NULL
                              REFERENCES SPECIFICATION.MEASURE(measure_id),

    stratification_dimension  VARCHAR(100)   NOT NULL COMMENT 'e.g., Region, Program Type, Age Group',
    stratification_value      VARCHAR(200)   NOT NULL COMMENT 'e.g., East, Foster Care, 0-5',

    numerator_value           NUMBER(12,4),
    denominator_value         NUMBER(12,4),
    result_value              NUMBER(12,4)   NOT NULL,
    performance_status        VARCHAR(20)
                              REFERENCES REFERENCE.LU_PERFORMANCE_STATUS(status_code),

    created_at                TIMESTAMP_NTZ  DEFAULT CURRENT_TIMESTAMP(),

    UNIQUE (result_id, stratification_dimension, stratification_value)
);
```

---

### Analytical Views

```sql
USE SCHEMA ANALYTICS;

-- =============================================================
-- VW_MEASURE_SCORECARD
-- The "current state" view — latest result per measure with
-- spec metadata joined in. This is your Power BI landing table.
-- =============================================================

CREATE OR REPLACE VIEW VW_MEASURE_SCORECARD AS
WITH latest_result AS (
    SELECT *,
           ROW_NUMBER() OVER (
               PARTITION BY measure_id
               ORDER BY period_end_date DESC
           ) AS rn
    FROM RESULTS.MEASURE_RESULT
)
SELECT
    m.measure_id,
    m.measure_title,
    m.measure_short_name,
    m.strategic_domain,
    m.strategic_objective,
    mt.type_label                   AS measure_type_label,
    st.scoring_label                AS scoring_type_label,
    pl.priority_label,
    m.unit_of_measure,
    dd.direction_label              AS desired_direction_label,

    -- Current result
    r.measurement_period,
    r.period_start_date,
    r.period_end_date,
    r.numerator_value,
    r.denominator_value,
    r.result_value,
    ps.status_label                 AS performance_status_label,
    ps.hex_color                    AS status_color,
    r.data_completeness_pct,
    r.analyst_notes,

    -- Targets for comparison
    m.target_value,
    tt.target_label                 AS target_type_label,
    m.benchmark_value,
    m.benchmark_source,
    m.performance_threshold_red,
    m.performance_threshold_yellow,

    -- Variance calculations
    r.result_value - m.target_value AS variance_from_target,
    CASE
        WHEN m.target_value != 0
        THEN ROUND((r.result_value - m.target_value) / m.target_value * 100, 2)
    END                             AS pct_variance_from_target,

    -- Governance
    m.measure_owner,
    m.measure_status,
    m.next_review_date,
    CASE
        WHEN m.next_review_date < CURRENT_DATE() THEN TRUE
        ELSE FALSE
    END                             AS review_overdue,

    r.reported_date,
    r.reported_by

FROM SPECIFICATION.MEASURE m
LEFT JOIN latest_result r
    ON m.measure_id = r.measure_id AND r.rn = 1
LEFT JOIN REFERENCE.LU_MEASURE_TYPE mt      ON m.measure_type = mt.type_code
LEFT JOIN REFERENCE.LU_SCORING_TYPE st      ON m.scoring_type = st.scoring_code
LEFT JOIN REFERENCE.LU_PRIORITY_LEVEL pl    ON m.priority_level = pl.priority_code
LEFT JOIN REFERENCE.LU_DESIRED_DIRECTION dd ON m.desired_direction = dd.direction_code
LEFT JOIN REFERENCE.LU_PERFORMANCE_STATUS ps ON r.performance_status = ps.status_code
LEFT JOIN REFERENCE.LU_TARGET_TYPE tt       ON m.target_type = tt.target_code
WHERE m.measure_status != 'retired';

-- =============================================================
-- VW_MEASURE_TREND
-- All results over time with period-over-period change.
-- Use this for trend charts in Power BI.
-- =============================================================

CREATE OR REPLACE VIEW VW_MEASURE_TREND AS
SELECT
    r.measure_id,
    m.measure_title,
    m.measure_short_name,
    m.strategic_domain,
    m.scoring_type,
    m.unit_of_measure,
    m.desired_direction,

    r.measurement_period,
    r.period_start_date,
    r.period_end_date,
    r.numerator_value,
    r.denominator_value,
    r.result_value,
    r.performance_status,
    r.data_completeness_pct,

    -- Period-over-period change
    LAG(r.result_value) OVER (
        PARTITION BY r.measure_id
        ORDER BY r.period_end_date
    )                               AS prior_period_value,

    r.result_value - LAG(r.result_value) OVER (
        PARTITION BY r.measure_id
        ORDER BY r.period_end_date
    )                               AS period_change,

    -- Target reference lines
    m.target_value,
    m.performance_threshold_red,
    m.performance_threshold_yellow,
    m.baseline_value

FROM RESULTS.MEASURE_RESULT r
JOIN SPECIFICATION.MEASURE m ON r.measure_id = m.measure_id
ORDER BY r.measure_id, r.period_end_date;

-- =============================================================
-- VW_DATA_LINEAGE
-- Shows every data element feeding each measure, with source
-- system info. Useful for impact analysis and data governance.
-- =============================================================

CREATE OR REPLACE VIEW VW_DATA_LINEAGE AS
SELECT
    m.measure_id,
    m.measure_title,
    m.measure_short_name,
    m.measure_status,

    de.data_element_id,
    de.element_name,
    de.element_description,
    det.type_label                  AS data_type_label,
    de.data_source_system,
    de.data_source_table_or_field,
    cm.method_label                 AS collection_method_label,
    cr.role_label                   AS role_in_calculation_label,
    de.is_required,
    de.data_quality_notes,
    de.responsible_party

FROM SPECIFICATION.DATA_ELEMENT de
JOIN SPECIFICATION.MEASURE m            ON de.measure_id = m.measure_id
LEFT JOIN REFERENCE.LU_DATA_ELEMENT_TYPE det ON de.data_type = det.type_code
LEFT JOIN REFERENCE.LU_COLLECTION_METHOD cm  ON de.collection_method = cm.method_code
LEFT JOIN REFERENCE.LU_CALC_ROLE cr          ON de.role_in_calculation = cr.role_code
ORDER BY m.measure_id, cr.role_code, de.element_name;

-- =============================================================
-- VW_MEASURE_HEALTH
-- Governance dashboard: which measures need attention?
-- =============================================================

CREATE OR REPLACE VIEW VW_MEASURE_HEALTH AS
WITH latest_result AS (
    SELECT measure_id,
           MAX(period_end_date)    AS last_result_date,
           MAX(reported_date)      AS last_reported_date
    FROM RESULTS.MEASURE_RESULT
    GROUP BY measure_id
),
element_counts AS (
    SELECT measure_id,
           COUNT(*)                AS total_elements,
           SUM(CASE WHEN data_quality_notes IS NOT NULL THEN 1 ELSE 0 END)
                                   AS elements_with_quality_flags
    FROM SPECIFICATION.DATA_ELEMENT
    GROUP BY measure_id
)
SELECT
    m.measure_id,
    m.measure_title,
    m.measure_status,
    m.measure_owner,
    m.priority_level,
    m.next_review_date,

    -- Review status
    CASE
        WHEN m.next_review_date < CURRENT_DATE() THEN 'OVERDUE'
        WHEN m.next_review_date < DATEADD(day, 30, CURRENT_DATE()) THEN 'DUE SOON'
        ELSE 'OK'
    END                             AS review_status,

    -- Data freshness
    lr.last_result_date,
    lr.last_reported_date,
    DATEDIFF(day, lr.last_result_date, CURRENT_DATE())
                                    AS days_since_last_result,

    -- Data element coverage
    ec.total_elements,
    ec.elements_with_quality_flags,

    -- Completeness flags
    CASE WHEN m.calculation_narrative IS NULL THEN FALSE ELSE TRUE END
                                    AS has_calc_narrative,
    CASE WHEN m.target_value IS NULL THEN FALSE ELSE TRUE END
                                    AS has_target,
    CASE WHEN m.measure_rationale IS NULL THEN FALSE ELSE TRUE END
                                    AS has_rationale

FROM SPECIFICATION.MEASURE m
LEFT JOIN latest_result lr ON m.measure_id = lr.measure_id
LEFT JOIN element_counts ec ON m.measure_id = ec.measure_id
WHERE m.measure_status NOT IN ('retired')
ORDER BY
    CASE m.priority_level
        WHEN 'critical'   THEN 1
        WHEN 'important'  THEN 2
        WHEN 'monitoring' THEN 3
    END,
    m.next_review_date;
```

---

### Stored Procedure: Result Ingestion with Auto RAG Calculation

```sql
USE SCHEMA RESULTS;

-- =============================================================
-- SP_UPSERT_MEASURE_RESULT
-- Inserts or updates a result and auto-calculates RAG status
-- based on the measure's threshold configuration.
-- =============================================================

CREATE OR REPLACE PROCEDURE SP_UPSERT_MEASURE_RESULT(
    P_MEASURE_ID        VARCHAR,
    P_MEASUREMENT_PERIOD VARCHAR,
    P_PERIOD_START      DATE,
    P_PERIOD_END        DATE,
    P_NUMERATOR         NUMBER,
    P_DENOMINATOR       NUMBER,
    P_RESULT_VALUE      NUMBER,
    P_COMPLETENESS_PCT  NUMBER,
    P_ANALYST_NOTES     VARCHAR,
    P_REPORTED_BY       VARCHAR
)
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
DECLARE
    v_status       VARCHAR;
    v_direction    VARCHAR;
    v_red          NUMBER;
    v_yellow       NUMBER;
    v_target       NUMBER;
BEGIN
    -- Fetch thresholds and direction from the measure spec
    SELECT desired_direction,
           performance_threshold_red,
           performance_threshold_yellow,
           target_value
    INTO v_direction, v_red, v_yellow, v_target
    FROM SPECIFICATION.MEASURE
    WHERE measure_id = :P_MEASURE_ID;

    -- Auto-calculate RAG status
    IF (v_red IS NOT NULL AND v_yellow IS NOT NULL) THEN
        IF (v_direction = 'increase') THEN
            -- Higher is better: red < yellow < green
            IF (:P_RESULT_VALUE < v_red) THEN
                v_status := 'red';
            ELSEIF (:P_RESULT_VALUE < v_yellow) THEN
                v_status := 'yellow';
            ELSE
                v_status := 'green';
            END IF;
        ELSEIF (v_direction = 'decrease') THEN
            -- Lower is better: green < yellow < red
            IF (:P_RESULT_VALUE > v_red) THEN
                v_status := 'red';
            ELSEIF (:P_RESULT_VALUE > v_yellow) THEN
                v_status := 'yellow';
            ELSE
                v_status := 'green';
            END IF;
        ELSE
            v_status := 'not_applicable';
        END IF;
    ELSE
        v_status := 'not_applicable';
    END IF;

    -- Upsert via MERGE
    MERGE INTO RESULTS.MEASURE_RESULT tgt
    USING (SELECT :P_MEASURE_ID AS measure_id,
                  :P_MEASUREMENT_PERIOD AS measurement_period) src
    ON tgt.measure_id = src.measure_id
       AND tgt.measurement_period = src.measurement_period
    WHEN MATCHED THEN UPDATE SET
        period_start_date     = :P_PERIOD_START,
        period_end_date       = :P_PERIOD_END,
        numerator_value       = :P_NUMERATOR,
        denominator_value     = :P_DENOMINATOR,
        result_value          = :P_RESULT_VALUE,
        performance_status    = v_status,
        data_completeness_pct = :P_COMPLETENESS_PCT,
        analyst_notes         = :P_ANALYST_NOTES,
        reported_date         = CURRENT_DATE(),
        reported_by           = :P_REPORTED_BY,
        updated_at            = CURRENT_TIMESTAMP()
    WHEN NOT MATCHED THEN INSERT (
        measure_id, measurement_period, period_start_date, period_end_date,
        numerator_value, denominator_value, result_value, performance_status,
        data_completeness_pct, analyst_notes, reported_date, reported_by
    ) VALUES (
        :P_MEASURE_ID, :P_MEASUREMENT_PERIOD, :P_PERIOD_START, :P_PERIOD_END,
        :P_NUMERATOR, :P_DENOMINATOR, :P_RESULT_VALUE, v_status,
        :P_COMPLETENESS_PCT, :P_ANALYST_NOTES, CURRENT_DATE(), :P_REPORTED_BY
    );

    RETURN 'Result saved for ' || :P_MEASURE_ID || ' / ' || :P_MEASUREMENT_PERIOD
           || ' — Status: ' || v_status;
END;
$$;
```

**Usage example:**

```sql
CALL RESULTS.SP_UPSERT_MEASURE_RESULT(
    'ORG-PM-001',       -- measure_id
    '2026-Q1',          -- measurement_period
    '2026-01-01',       -- period_start
    '2026-03-31',       -- period_end
    187,                -- numerator
    205,                -- denominator
    91.2,               -- result_value
    98.5,               -- completeness_pct
    'Spike due to backlog clearance from prior quarter',
    'J. Smith'          -- reported_by
);
-- Returns: 'Result saved for ORG-PM-001 / 2026-Q1 — Status: green'
```

---

### Access Control Pattern

```sql
-- =============================================================
-- ROLE-BASED ACCESS
-- =============================================================

-- Analysts: can read everything, write results
CREATE ROLE IF NOT EXISTS PM_ANALYST;
GRANT USAGE ON DATABASE PERFORMANCE_MEASURES TO ROLE PM_ANALYST;
GRANT USAGE ON ALL SCHEMAS IN DATABASE PERFORMANCE_MEASURES TO ROLE PM_ANALYST;
GRANT SELECT ON ALL TABLES IN SCHEMA SPECIFICATION TO ROLE PM_ANALYST;
GRANT SELECT ON ALL TABLES IN SCHEMA REFERENCE TO ROLE PM_ANALYST;
GRANT SELECT ON ALL VIEWS IN SCHEMA ANALYTICS TO ROLE PM_ANALYST;
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA RESULTS TO ROLE PM_ANALYST;

-- Measure developers: can also modify specifications
CREATE ROLE IF NOT EXISTS PM_DEVELOPER;
GRANT ROLE PM_ANALYST TO ROLE PM_DEVELOPER;
GRANT INSERT, UPDATE ON ALL TABLES IN SCHEMA SPECIFICATION TO ROLE PM_DEVELOPER;

-- Admins: full control including reference data
CREATE ROLE IF NOT EXISTS PM_ADMIN;
GRANT ROLE PM_DEVELOPER TO ROLE PM_ADMIN;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA REFERENCE TO ROLE PM_ADMIN;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA SPECIFICATION TO ROLE PM_ADMIN;
```

---

### Snowflake-Specific Features to Leverage

**Time Travel for audit trails.** With `DATA_RETENTION_TIME_IN_DAYS = 90` on the database, you can query any table as it existed at a prior point in time. This gives you a built-in audit trail without needing to build your own slowly-changing-dimension logic for the specification tables:

```sql
-- What did this measure's spec look like 30 days ago?
SELECT * FROM SPECIFICATION.MEASURE AT(OFFSET => -60*60*24*30)
WHERE measure_id = 'ORG-PM-001';
```

**Zero-copy cloning for testing.** When piloting spec changes, clone the SPECIFICATION schema to a sandbox without duplicating storage:

```sql
CREATE SCHEMA SPECIFICATION_TEST CLONE SPECIFICATION;
-- Make changes, validate, then swap or drop
```

**Tags for governance.** Snowflake object tags can layer additional classification onto columns:

```sql
CREATE TAG IF NOT EXISTS PII_FLAG ALLOWED_VALUES 'yes', 'no';
ALTER TABLE SPECIFICATION.MEASURE
    MODIFY COLUMN measure_owner SET TAG PII_FLAG = 'yes';
```

**Streams + Tasks for automation.** If you want downstream processes (e.g., refreshing a Power BI dataset or sending Slack alerts) triggered when new results land:

```sql
CREATE STREAM RESULTS_STREAM ON TABLE RESULTS.MEASURE_RESULT;

CREATE TASK CHECK_NEW_RESULTS
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = 'USING CRON 0 8 * * MON America/New_York'
AS
    -- Example: flag any red-status results from the past week
    SELECT mr.measure_id, m.measure_title, mr.result_value, mr.performance_status
    FROM RESULTS_STREAM mr
    JOIN SPECIFICATION.MEASURE m ON mr.measure_id = m.measure_id
    WHERE mr.performance_status = 'red'
      AND METADATA$ACTION = 'INSERT';
```

---

### Connecting to Power BI

The analytical views are designed to be your Power BI DirectQuery or Import source. Recommended dataset structure:

| Power BI Table | Snowflake Source | Refresh Pattern |
|---|---|---|
| Scorecard (current state) | `ANALYTICS.VW_MEASURE_SCORECARD` | Daily or on-demand |
| Trend (time series) | `ANALYTICS.VW_MEASURE_TREND` | After each reporting cycle |
| Data Lineage | `ANALYTICS.VW_DATA_LINEAGE` | Weekly |
| Measure Health | `ANALYTICS.VW_MEASURE_HEALTH` | Daily |
| Stratified Results | `RESULTS.MEASURE_RESULT_STRATIFIED` joined to spec | After each reporting cycle |

Use the Snowflake ODBC or native Power BI Snowflake connector. For datasets under a few hundred thousand rows (likely for 34 measures × a few years of quarterly results), Import mode with scheduled refresh will give you the best dashboard performance.

---

## Recommended Next Steps

1. **Stand up the Snowflake schemas.** Run the DDL from the Snowflake Implementation section to create the database, reference tables, core tables, and views. This is a one-time setup.

2. **Seed the reference tables.** The INSERT statements for lookup tables are included in the DDL. Review them with your team — you may want to add domain-specific values (e.g., additional `strategic_domain` categories).

3. **Populate the Measure table for all 34 measures.** Start with identity, classification, and scoring fields. Population definitions and calculation narratives can be "TBD" initially — the schema allows NULLs where appropriate.

4. **Write calculation narratives for your top 5 measures first.** Use the example format from the Calculation Logic section. These become the template for the remaining 29.

5. **Add Data Elements incrementally.** For each measure, list the 3-5 key data inputs. Full source-system mapping can come later as you trace lineage.

6. **Connect Power BI to the ANALYTICS views.** Use the Snowflake connector with Import mode and scheduled refresh. The VW_MEASURE_SCORECARD view is designed to be your primary landing table for a scorecard dashboard.

7. **Establish a review cadence.** Even annual review of specifications keeps them from drifting away from operational reality. The VW_MEASURE_HEALTH view will flag overdue reviews automatically.
