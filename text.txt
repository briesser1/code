# Literature Review: Hierarchical Sentence Clustering with LLM Embeddings

## Overview

This literature review surveys the foundational theory, methods, and real-world applications of divisive hierarchical clustering (DIANA) combined with language model embeddings for text and sentence clustering. Sources span foundational textbooks, survey papers, embedding-specific research, healthcare/clinical NLP, and legal domain applications.

---

## 1. Foundational Theory

### 1.1 Finding Groups in Data: An Introduction to Cluster Analysis
**Kaufman, L., & Rousseeuw, P. J. (1990).** *Finding Groups in Data: An Introduction to Cluster Analysis.* John Wiley & Sons. ISBN: 0-471-73578-7.

The foundational textbook that introduced the DIANA (DIvisive ANAlysis) algorithm for divisive hierarchical clustering. Chapter 6 provides the complete specification of DIANA, which constructs a hierarchy by starting with one large cluster containing all observations and recursively dividing clusters until each contains a single observation. The algorithm identifies the cluster with the largest diameter, finds its most dissimilar object (the "splinter"), and iteratively reassigns objects closer to the splinter than to the remaining group. DIANA provides a divisive coefficient measuring clustering structure and introduces the "banner," a graphical display for hierarchical structure.

[Wiley Online Library](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316801)

### 1.2 A Comparison of Document Clustering Techniques
**Steinbach, M., Karypis, G., & Kumar, V. (2000).** "A Comparison of Document Clustering Techniques." *KDD Workshop on Text Mining.* University of Minnesota.

A seminal comparison study evaluating three agglomerative hierarchical schemes against partitional methods like K-means and bisecting K-means on text data. Key finding: hierarchical clustering is accurate but computationally expensive (over an hour for 3,204 documents vs. under a minute for bisecting K-means). The study notes that early mistakes in hierarchical clustering cannot be corrected and that hierarchical-K-means hybrids can improve efficiency. Directly relevant for understanding the computational trade-offs when choosing DIANA for text clustering.

[PDF](https://www.stat.cmu.edu/~rnugent/PCMI2016/papers/DocClusterComparison.pdf)

---

## 2. Survey Papers

### 2.1 Comprehensive Survey on Hierarchical Clustering Algorithms and Recent Developments
**Artificial Intelligence Review (2023).** Vol. 56, pp. 8219-8264. Springer.

A comprehensive 2023 survey covering both agglomerative and divisive hierarchical clustering algorithms with developments through 2022. Discusses key issues including cluster selection for splitting in divisive methods, similarity measures for merging in agglomerative methods, and the advantage that hierarchical methods provide multiple consistent partitions at different levels without rerunning clustering. Essential reading for understanding the current state of hierarchical clustering research and where DIANA fits within the broader algorithmic landscape.

[Springer Link](https://link.springer.com/article/10.1007/s10462-022-10366-3)

### 2.2 A Comprehensive and Analytical Review of Text Clustering Techniques
**Mehta, V., Agarwal, S., & Kaliyar, R. (2024).** "A Comprehensive and Analytical Review of Text Clustering Techniques." *International Journal of Data Science and Analytics,* Vol. 18, pp. 239-258. Springer.

This 2024 review traces the evolution from traditional non-semantic text clustering (TF-IDF, bag-of-words) to state-of-the-art semantic techniques using deep learning. It analyzes methods both theoretically and experimentally, providing a modern perspective on hierarchical clustering in the context of information retrieval. Particularly useful for understanding why transformer-based embeddings produce superior clustering results compared to traditional feature extraction methods.

[Springer Link](https://link.springer.com/article/10.1007/s41060-024-00540-x)

### 2.3 Short Text Clustering Algorithms, Application and Challenges: A Survey
**Applied Sciences (2023).** Vol. 13, No. 1, Article 342. MDPI.

This survey addresses the specific challenge of clustering short texts from social media, clinical notes, and other sources that suffer from sparsity and lack of context. It describes hierarchical clustering as "the standard method for document clustering" that produces nested groups, and evaluates similarity measures including cosine similarity, Jaccard coefficient, and Dice coefficient. Directly relevant to clustering tasks involving brief clinical descriptions or sentence-level text.

[MDPI](https://www.mdpi.com/2076-3417/13/1/342)

### 2.4 Incremental Hierarchical Text Clustering Methods: A Review
**arXiv preprint (2023).** arXiv:2312.07769.

The first survey specifically focused on incremental hierarchical clustering methods for text documents. It systematically reviews works from ACM, ScienceDirect, Springer Link, and IEEE Xplore that use hierarchical clustering for dynamic text data and data streams. The review compares techniques like ICHTC-CF (an agglomerative method using CFu-Trees) and discusses how incremental methods handle evolving document collections --- an important consideration for production clinical NLP systems where new records arrive continuously.

[arXiv](https://arxiv.org/html/2312.07769v1)

---

## 3. Sentence Embeddings and Hierarchical Clustering

### 3.1 Application and Evaluation of Sentence Embedding and Clustering Methods in the Context of Concept Hierarchy Construction
**Procedia Computer Science (2023).** Elsevier / ACM.

This paper proposes approaches for constructing concept hierarchies from short sentences using sentence embeddings combined with clustering and automatic labeling. The study found that hierarchical clustering was the best-performing method when combined with embedding-based similarity measures, significantly improving performance in both text clustering and summarization tasks. The superior performance stems from more effective use of semantic information captured by embedding models compared to traditional keyword-based approaches.

[ScienceDirect](https://www.sciencedirect.com/science/article/pii/S1877050923015016)

### 3.2 Experimental Study on Short-Text Clustering Using Transformer-Based Semantic Similarity Measure
**PMC (2024).** Article ID: PMC11157522.

This experimental study demonstrates how BERT and other transformer-based models revolutionized text clustering by providing richer semantic representations through bidirectional context. The study shows that modern LLM embeddings (Sentence-BERT, GPT-based) combined with dimensionality reduction techniques (UMAP) before hierarchical clustering greatly improve results compared to traditional TF-IDF approaches. Directly validates the empirical finding that transformer embeddings resolve the "mega-cluster" problem observed with TF-IDF in divisive hierarchical clustering.

[PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC11157522/)

### 3.3 HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization
**arXiv preprint (2025).** arXiv:2506.19992.

HERCULES presents a state-of-the-art framework combining hierarchical clustering, K-Means, LLMs, and embedding models to create interpretable hierarchies with LLM-generated titles and descriptions for each node. This represents the current frontier in combining sentence embeddings with hierarchical structure for document organization and summarization, with demonstrated applications in customer service and content management systems.

[arXiv](https://arxiv.org/html/2506.19992)

---

## 4. Healthcare and Clinical Text Applications

### 4.1 Natural Language Processing of Clinical Notes on Chronic Diseases: Systematic Review
**JMIR Medical Informatics (2019).** Vol. 7, No. 2, e12239.

A comprehensive systematic review examining NLP methods applied to clinical notes for chronic diseases. Of 2,652 articles screened, 106 met inclusion criteria covering 43 chronic diseases across 10 ICD-10 categories. The review found a significant increase in machine learning methods over rule-based approaches for clinical text analysis. Essential reading for understanding the clinical NLP landscape and where hierarchical clustering fits within the broader toolkit for medical text mining.

[JMIR](https://medinform.jmir.org/2019/2/e12239/)

### 4.2 SymptomGraph: Identifying Symptom Clusters from Narrative Clinical Notes Using Graph Clustering
**ACM/SIGAPP Symposium on Applied Computing (2023).** ACM.

SymptomGraph uses NLP and AI to extract symptoms from EHR clinical notes, then applies a universal sentence encoder to convert symptom expressions into embeddings followed by hierarchical clustering with cosine distance to discover typical symptom clusters. Applied to colorectal cancer patients, it revealed that patients with diabetes show more peripheral neuropathy symptoms, younger patients exhibit mental dysfunction patterns, and late-stage patients show more memory loss. This pipeline --- sentence encoder, cosine distance, hierarchical clustering on clinical text --- closely mirrors the approach used in this project.

[ACM Digital Library](https://dl.acm.org/doi/10.1145/3555776.3577685)

### 4.3 Applying Text-Mining to Clinical Notes: The Identification of Patient Characteristics from Electronic Health Records
**BMC Medical Informatics and Decision Making (2025).** BMC/Springer.

This recent study demonstrates the feasibility of text-mining for extracting patient characteristics (language barriers, living alone, cognitive frailty, non-adherence) from EHRs. The study compared rule-based SQL queries vs. Named Entity Recognition (NER) models, finding that NER models outperform rule-based approaches for complex clinical terminology. Shows practical implementation of clinical text mining with hierarchical analysis of patient profiles.

[BMC](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-025-03137-x)

### 4.4 Optimizing Patient Stratification in Healthcare: A Comparative Analysis of Clustering Algorithms for EHR Data
**International Journal of Computational Intelligence Systems (2024).** Springer.

A comparative analysis of clustering algorithms including hierarchical clustering for patient stratification using EHR data. Hierarchical clustering is described as organizing data into a tree-like structure without requiring a fixed number of clusters, allowing natural visualization of dataset relationships. The study emphasizes hierarchical methods' strength in patient categorization and personalized medicine applications, where the dendrogram reveals clinically meaningful subgroups at multiple granularities.

[Springer Link](https://link.springer.com/article/10.1007/s44196-024-00568-8)

### 4.5 From Free Text to Clusters of Content in Health Records: An Unsupervised Graph Partitioning Approach
**Applied Network Science (2018).** Springer Open.

This paper applies network-theoretical tools and multiscale community detection to analyze free text in NHS Hospital Patient Incident reports. The unsupervised approach finds clusters of reports at different resolution levels, allowing content categories to emerge from textual data rather than fitting pre-designed classifications. Demonstrates how hierarchical and multi-resolution clustering helps mitigate human error in complex classification trees commonly used in clinical settings.

[Springer Open](https://appliednetsci.springeropen.com/articles/10.1007/s41109-018-0109-9)

### 4.6 Towards Domain Specification of Embedding Models in Medicine
**arXiv preprint (2025).** arXiv:2507.19407.

This paper evaluates general-purpose vs. medical-domain embedding models (BGE, SciBERT, MiniLM, ClinicalBERT, BioSimCSE, MedTE) for healthcare NLP tasks including clustering. Key finding: self-supervised contrastive learning is decisive for specialized domains like healthcare --- domain-specific contrastive models consistently outperform general-purpose ones for medical clustering, classification, and retrieval. Critically important for anyone applying sentence embeddings to medical text clustering; suggests that models like `all-MiniLM-L6-v2` may underperform compared to medical-domain alternatives.

[arXiv](https://arxiv.org/html/2507.19407v2)

### 4.7 Evolution of AI Enabled Healthcare Systems Using Textual Data with a Pretrained BERT Deep Learning Model
**Scientific Reports (2025).** Nature.

This 2025 study introduces a self-supervised text mining approach using BERT to explore AI trends in healthcare, analyzing 1,587 scientific papers and 1,314 patents from 2018-2022. The BERT-based clustering and trend analysis revealed steady increases in topics like diabetes monitoring, cardiac monitoring, and clinical data analysis. Demonstrates state-of-the-art integration of pre-trained transformers with hierarchical topic clustering for healthcare research intelligence.

[Nature Scientific Reports](https://www.nature.com/articles/s41598-025-91622-8)

---

## 5. Legal and Other Real-World Applications

### 5.1 Legal Documents Clustering and Summarization Using Hierarchical Latent Dirichlet Allocation
**Venkatesh et al. (2017).** *IAES International Journal of Artificial Intelligence,* Vol. 6, No. 3.

This paper clusters legal judgments based on topics obtained from hierarchical LDA (hLDA) using similarity measures between topics and documents, also providing document summarization. Applied to diverse legal sections including Sales Tax, Rent Control, Motor Vehicle, Family Law, Patent, Trademark, Company Law, Taxation, Property, and Cyber Law. Demonstrates how hierarchical topic modeling enables legal document organization at multiple levels of specificity.

[ResearchGate](https://www.researchgate.com/publication/314795994)

### 5.2 PRILJ: Identification of Regularities in Legal Case Judgments
**Artificial Intelligence and Law (2021).** Springer.

PRILJ identifies paragraph regularities in legal case judgments to support legal experts during document redaction. It uses a two-step approach: first grouping documents into clusters by semantic content, then identifying paragraph regularities per cluster. The study found particularly promising results with hierarchical clustering methods where clusters are organized hierarchically, and with overlapping clustering where documents can belong to multiple clusters --- a natural property of legal documents that span multiple topical areas.

[Springer Link](https://link.springer.com/article/10.1007/s10506-021-09297-1)

### 5.3 Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents
**arXiv preprint (2024).** arXiv:2403.06872.

This paper presents MESc (Multi-stage Encoder-based Supervised with-clustering), a hierarchical classification framework for large legal documents. It divides documents into parts, extracts embeddings from a custom fine-tuned LLM, and approximates document structure through unsupervised clustering. Achieved new baselines on ILDC and LexGLUE benchmarks (ECtHR A/B, SCOTUS), demonstrating how hierarchical clustering integrates with modern LLMs for practical legal NLP.

[arXiv](https://arxiv.org/html/2403.06872)

---

## References Summary

| # | Citation | Year | Domain | Source |
|---|---------|------|--------|--------|
| 1 | Kaufman & Rousseeuw | 1990 | Theory | Wiley |
| 2 | Steinbach, Karypis & Kumar | 2000 | Text Comparison | KDD Workshop |
| 3 | Hierarchical Clustering Survey | 2023 | Survey | AI Review / Springer |
| 4 | Mehta et al. | 2024 | Survey | Springer |
| 5 | Short Text Clustering Survey | 2023 | Survey | MDPI |
| 6 | Incremental Hierarchical Clustering | 2023 | Survey | arXiv |
| 7 | Sentence Embedding + Hierarchy | 2023 | Embeddings | Elsevier |
| 8 | Transformer Short-Text Clustering | 2024 | Embeddings | PMC |
| 9 | HERCULES | 2025 | Embeddings | arXiv |
| 10 | Clinical Notes NLP Review | 2019 | Healthcare | JMIR |
| 11 | SymptomGraph | 2023 | Healthcare | ACM |
| 12 | Text-Mining Clinical Notes | 2025 | Healthcare | BMC |
| 13 | Patient Stratification | 2024 | Healthcare | Springer |
| 14 | Free Text Health Records | 2018 | Healthcare | Springer Open |
| 15 | Medical Embedding Models | 2025 | Healthcare | arXiv |
| 16 | BERT Healthcare AI | 2025 | Healthcare | Nature |
| 17 | Legal Docs hLDA | 2017 | Legal | IAES |
| 18 | PRILJ Legal Judgments | 2021 | Legal | Springer |
| 19 | LLMs for Legal Classification | 2024 | Legal | arXiv |
