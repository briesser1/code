
# Artificial Intelligence in Healthcare & Social Services: A Comprehensive Report

## Executive Summary

This report examines the current state of artificial intelligence in healthcare and social services, covering five major areas: (1) the fundamental differences between traditional machine learning approaches and generative AI powered by large language models; (2) cutting-edge methods for deploying LLM-based applications including orchestration frameworks, embeddings, and database technologies; (3) real-world use cases of AI deployment in healthcare settings, including both successes and notable failures; (4) AI deployments in social services and foster care; and (5) how large language models actually store and retrieve knowledge.

**Key Findings:**
- Healthcare AI spending reached **$1.4 billion** in 2025, nearly tripling 2024's investment [3.2]
- **22%** of healthcare organizations have implemented domain-specific AI tools (7x increase over 2024) [3.2]
- **77%** of U.S. hospitals use ambient AI documentation solutions [3.1]
- **46%** of children in foster care are served by agencies using Binti's AI-powered platform [4.6, 4.7]
- Traditional ML and generative AI serve **different but complementary** purposes [1.4]
- **Encoder models (BERT)** excel at classification and NER; **decoder models (LLMs)** excel at generation [2.18, 2.22]
- Fine-tuned BERT outperforms ChatGPT for medical specialty classification (F1: 0.587 vs. 0.134) [2.22]
- LLMs store knowledge in **billions of numerical parameters**—not databases [5.1, 5.4]
- The IBM Watson for Oncology failure (**$4 billion loss**) provides critical lessons [3.3]

---

## Section 1: Machine Learning vs. Generative AI

### 1.1 The AI Hierarchy

Understanding the relationship between different AI paradigms is essential for making informed technology decisions in healthcare [1.4]. Artificial Intelligence serves as the umbrella term encompassing all systems designed to simulate human intelligence. Machine Learning is a subset of AI focused on systems that learn from data without explicit programming. Deep Learning, in turn, is a subset of Machine Learning using multi-layer neural networks. Generative AI represents the newest frontier—AI systems capable of creating new content.

**The Nested Hierarchy:**
| Level | Technology | Description |
|-------|------------|-------------|
| 1 (Broadest) | Artificial Intelligence | Systems simulating human intelligence |
| 2 | Machine Learning | Learning from data without explicit programming |
| 3 | Deep Learning | Multi-layer neural networks |
| 4 (Narrowest) | Generative AI / LLMs | Creates new content (text, images, code) |

*Note: Each level is a subset of the one above it.*

### 1.2 Traditional Machine Learning

Traditional machine learning algorithms, including XGBoost, Random Forests, and Support Vector Machines, have been the workhorses of healthcare analytics for over a decade [1.1]. These approaches excel when working with structured, tabular data—the kind commonly found in electronic health records (EHRs), lab results, and administrative databases.

**XGBoost (Extreme Gradient Boosting)** is a particularly powerful algorithm based on boosted decision trees [1.1, 1.3]. It is especially effective for structured datasets and scenarios where interpretability and computational efficiency are paramount. Unlike deep learning approaches, XGBoost requires significant hands-on effort in feature engineering—the manual process of selecting and transforming input variables to improve model performance.

**Key Characteristics of Traditional ML:**
- Works best with smaller, highly curated datasets
- Requires manual feature engineering
- Produces point estimates or probabilistic predictions
- Offers higher interpretability (especially tree-based models)
- More computationally efficient than deep learning alternatives
- Well-suited for tasks like patient risk stratification, readmission prediction, and resource utilization forecasting

### 1.3 Deep Learning and Neural Networks

Deep Learning represents a significant evolution from traditional machine learning. Using artificial neural networks with multiple layers (hence "deep"), these systems can learn complex patterns and hierarchical representations from vast amounts of data. Inspired by the structure of the human brain, deep neural networks excel at handling unstructured data—images, audio, and text—that would be difficult to process with traditional approaches.

In healthcare, deep learning has achieved remarkable success in medical imaging applications. Convolutional Neural Networks (CNNs) can detect diabetic retinopathy, identify tumors in radiology images, and analyze pathology slides with accuracy matching or exceeding human specialists in specific narrow tasks.

### 1.4 Generative AI and Large Language Models

Generative AI represents a paradigm shift in artificial intelligence [1.2]. While traditional AI excels at analyzing and interpreting existing data, generative AI can create entirely new content—text, images, code, and more—based on patterns learned from massive training datasets [1.3].

Large Language Models (LLMs) are the most prominent form of generative AI in healthcare applications. Models like GPT-4, Claude, and specialized variants like Med-PaLM can process and generate natural language, enabling applications from clinical documentation to patient communication to literature review [1.5].

**Key Characteristics of Generative AI/LLMs:**
- Trained on internet-scale datasets (billions of parameters)
- Generate natural language responses, images, or other content
- Demonstrate emergent capabilities and in-context learning
- Extremely compute-intensive to train and operate
- Can handle complex, multi-step reasoning tasks

**Healthcare-Specific LLMs:**
- **Med-PaLM** (Google): Specialized for medical question-answering
- **BioGPT** (Microsoft): Pre-trained on biomedical literature
- **Clinical BERT**: Fine-tuned on clinical notes and EHR data

### 1.5 When to Use Which Approach

The choice between traditional ML and generative AI is not binary—it depends on the specific use case:

| Factor | Choose Traditional ML | Choose Generative AI |
|--------|----------------------|---------------------|
| Data Type | Structured, tabular data | Unstructured text |
| Key Requirement | Interpretability is critical | Natural language output needed |
| Compute Resources | Limited compute available | High compute available |
| Primary Task | Prediction, classification | Documentation, Q&A |
| Example Use Cases | Risk scoring, readmission prediction | Clinical note generation, literature search |

As noted by MIT Sloan researchers [1.5], "GPT-4 and similar models can be more accurate than a custom-built machine learning model, and you can get an application up and running much sooner." However, LLMs may not be as accurate for highly technical or niche tasks where traditional ML trained on domain-specific data remains superior.

---

## Section 2: Cutting-Edge LLM Methods and Infrastructure

### 2.1 LLM Orchestration Frameworks

The complexity of modern AI applications has spawned an ecosystem of orchestration frameworks designed to manage LLM interactions, tool use, and multi-step workflows.

| Framework | Year | Key Stats | Best For |
|-----------|------|-----------|----------|
| LangChain | 2023 | 80K+ GitHub stars | RAG applications, prototyping |
| LangGraph | 2024 | GA May 2025; 400+ companies | Production multi-agent systems |
| LlamaIndex | 2024 | 100+ data connectors | Document-heavy RAG |
| CrewAI | 2024 | Role-based architecture | Multi-agent orchestration |
| Claude Code | 2025 | Terminal-based | Agentic coding, DevOps |

#### LangChain

LangChain emerged as the dominant framework in 2023, accumulating over 80,000 GitHub stars [2.1]. Its core innovation is the ability to compose LLM calls with other operations (database queries, API calls, document retrieval) using a simple pipe (|) operator. State management uses flexible Python dictionaries, making it ideal for rapid prototyping.

However, the LangChain team has publicly pivoted, now recommending: "Use LangGraph for agents, not LangChain." [2.1] LangChain remains excellent for RAG (Retrieval-Augmented Generation) applications but is no longer the recommended choice for complex agent workflows.

#### LangGraph

LangGraph reached General Availability in May 2025 and now powers production agents at nearly 400 companies [2.2]. The framework models workflows as graphs—with nodes representing tools, functions, LLMs, or subgraphs, and edges defining the flow logic (including loops and conditional routes).

**Notable LangGraph Deployments:**
- LinkedIn built an AI recruiter automating candidate sourcing
- Uber uses LangGraph for large-scale code migrations
- Replit's AI copilot that builds software from scratch runs on LangGraph

LangGraph excels at complex workflows requiring multiple branches, retries, and cycles—essential for robust healthcare AI applications.

#### Claude Code

Claude Code is Anthropic's agentic coding tool that operates directly in the terminal [2.3]. Unlike browser-based alternatives, it integrates with existing developer workflows and can understand entire codebases. Key features include:

- Full codebase understanding and context
- Git operations through natural language commands
- Checkpoint system for code recovery
- Subagents for parallel development tasks
- DevOps workflow support (testing, debugging, deployment)

Many engineers report using Claude for 90%+ of their git interactions, including commit message generation, conflict resolution, and complex refactoring operations.

#### Model Context Protocol (MCP)

The Model Context Protocol is an open standard introduced by Anthropic in November 2024 that has rapidly become the industry standard for connecting AI models to external tools and data sources [2.4]. Often called "USB-C for AI," MCP provides a universal interface that allows any AI model to communicate with any tool through a single, standardized protocol [2.6].

**Industry Adoption (as of late 2025) [2.7]:**
- OpenAI adopted MCP in March 2025 across ChatGPT products
- Google DeepMind confirmed MCP support for Gemini in April 2025
- Microsoft and GitHub joined MCP's steering committee in May 2025
- Donated to Linux Foundation's Agentic AI Foundation in December 2025
- 97M+ monthly SDK downloads, 5,800+ MCP servers available

**MCP Solves the Integration Complexity Problem:**

| Aspect | Without MCP (M×N) | With MCP (M+N) |
|--------|-------------------|----------------|
| Integration Model | Each app connects to each tool directly | Apps connect to MCP; tools connect to MCP |
| Example | 3 apps × 3 tools = 9 custom integrations | 3 apps + 3 tools = 6 standard integrations |
| At Scale | 10 apps × 100 tools = 1,000 integrations | 10 apps + 100 tools = 110 integrations |
| Adding New Tool | Must update all apps | Tool connects once to MCP; all apps can use it |

### 2.2 Local LLMs: Running Models On-Premises

For organizations with strict data privacy requirements—particularly in healthcare—running LLMs locally rather than through cloud APIs offers significant advantages [2.11].

**Cloud API vs. Local LLM Deployment:**

| Factor | Cloud API (GPT-4, Claude) | Local LLM (Llama, Mistral) |
|--------|---------------------------|---------------------------|
| Model capability | Cutting-edge, largest models | Good performance for most tasks |
| Setup | No hardware needed, easy to start | Data never leaves your network |
| Compliance | Requires BAA, careful handling | HIPAA/GDPR compliant by design |
| Cost model | Pay per token | No per-query costs after setup |
| Data privacy | Data leaves your network | Complete data control |

**Key Privacy Benefits [2.11, 2.12]:**
- **Zero data exposure**: All processing happens on your hardware—patient data never leaves your network
- **Compliance by design**: HIPAA, GDPR, and SOC 2 requirements met automatically
- **Air-gapped deployment**: Can run in completely isolated environments
- **Audit-ready**: Complete control over data processing documentation

**Local LLM Deployment Options [2.10, 2.14]:**

| Tool | Best For | Key Features |
|------|----------|--------------|
| Ollama | Development, prototyping | Simple CLI, runs Llama/Mistral/Qwen, MIT licensed, no telemetry |
| vLLM | Production multi-user serving | 3x better throughput than Ollama, enterprise-grade performance |
| llama.cpp | Maximum control, edge devices | C++ implementation, runs on CPU, highly customizable |
| LM Studio | Desktop users, non-developers | GUI interface, easy model management |

**Hybrid Approach:** Many healthcare organizations adopt a hybrid strategy—using local LLMs for sensitive tasks (analyzing patient records, processing clinical notes) while using cloud APIs for general tasks (literature search, administrative content generation) [2.13].

### 2.3 Encoder Models (BERT) vs. Decoder Models (Local LLMs)

A critical architectural distinction in modern AI is between encoder-only models (like BERT) and decoder-only models (like Llama and Mistral) [2.18, 2.19]. Understanding this difference is essential for selecting the right tool for healthcare applications.

#### Architectural Foundations

Both BERT and modern LLMs are built on the Transformer architecture introduced in 2017, but they use different components [2.18]:

**BERT (Bidirectional Encoder Representations from Transformers):**
- Uses only the encoder portion of the Transformer
- Processes text bidirectionally—seeing context from both left and right simultaneously
- Trained using Masked Language Modeling (MLM): predicting randomly masked words
- Produces rich contextual embeddings for downstream tasks
- Introduced by Google in 2018

**Local LLMs (Llama, Mistral, etc.):**
- Use only the decoder portion of the Transformer
- Process text causally—left-to-right, one token at a time
- Trained using next-token prediction: predicting the next word given previous words
- Designed for text generation
- Modern variants range from 7B to 405B parameters

**Architectural Comparison:**

| Aspect | BERT (Encoder-Only) | Local LLMs (Decoder-Only) |
|--------|---------------------|---------------------------|
| Architecture | Transformer encoder stack | Transformer decoder stack |
| Attention Pattern | Bidirectional (sees full context) | Causal (left-to-right only) |
| Training Objective | Masked Language Modeling | Next-token prediction |
| Primary Output | Embeddings, classifications | Generated text |
| Parameter Count | 110M–395M | 7B–405B |
| Context Window | 512 tokens (original); 8K (ModernBERT) | 4K–128K tokens |

#### When to Use BERT-Style Encoder Models

Encoder models excel at **understanding** and **classification** tasks [2.20, 2.21]:

- **Text Classification**: Sentiment analysis, intent detection, medical coding (ICD-10), triage prioritization
- **Named Entity Recognition (NER)**: Extracting medications, diagnoses, procedures, and patient identifiers from clinical notes
- **Semantic Search**: Creating high-quality embeddings for RAG retrieval systems
- **Sentence Similarity**: Matching similar clinical cases or research papers
- **Question Answering**: Extractive QA where answers exist verbatim in source text

**Healthcare Research Finding:** A 2024 study comparing fine-tuned BERT (KM-BERT) vs. ChatGPT for medical specialty recommendations found BERT achieved significantly higher accuracy (0.977 vs. 0.939), precision (0.570 vs. 0.219), and F1-score (0.587 vs. 0.134) [2.22].

#### When to Use Decoder Models (Local LLMs)

Decoder models excel at **generation** and **reasoning** tasks [2.19, 2.20]:

- **Text Generation**: Clinical note drafting, discharge summaries, patient communication letters
- **Conversational AI**: Medical chatbots, patient Q&A systems, clinical decision support dialogues
- **Zero-shot/Few-shot Learning**: Handling new tasks without fine-tuning by providing examples in the prompt
- **Complex Reasoning**: Multi-step clinical reasoning, differential diagnosis exploration
- **Summarization**: Condensing lengthy medical records or research papers
- **Open-ended Responses**: Explaining conditions to patients, generating care instructions

**LLM Advantage:** While ChatGPT scored lower on structured classification, it excelled at providing "detailed, contextually appropriate explanations" that enhance patient comprehension [2.22].

#### Healthcare-Specific BERT Models

The biomedical and clinical NLP communities have developed specialized BERT variants [2.23, 2.24, 2.25]:

| Model | Training Data | Parameters | Best For |
|-------|---------------|------------|----------|
| BioBERT | PubMed abstracts + PMC full text | 110M | Biomedical literature mining, entity extraction |
| ClinicalBERT | MIMIC-III clinical notes | 110M | EHR analysis, clinical NER |
| PubMedBERT | PubMed only (from scratch) | 110M | Biomedical NLP (outperforms mixed-domain models) |
| BlueBERT | PubMed + MIMIC-III | 110M | Combined biomedical and clinical tasks |
| Clinical ModernBERT | MIMIC-IV + PubMed + ontologies | 149M–395M | Long clinical documents (8K context) |

**Key Finding:** Microsoft Research demonstrated that domain-specific pretraining from scratch (PubMedBERT) outperforms models pretrained on general text then adapted to biomedicine [2.24].

#### Resource Requirements Comparison

The computational requirements differ dramatically between these model types [2.26, 2.27]:

| Factor | BERT Fine-tuning | LLM Inference | LLM Fine-tuning |
|--------|------------------|---------------|-----------------|
| GPU Memory | 8–16 GB | 14–80 GB | 40–160+ GB |
| Training Time | Hours | N/A (prompting) | Days to weeks |
| Hardware | Consumer GPU (RTX 3080) | Gaming/Pro GPU (RTX 4090, A100) | Enterprise GPU (A100, H100) |
| Relative Cost | Low | Medium | High |

**Memory Rule of Thumb:**
- BERT fine-tuning: ~2-4 GB per 100M parameters
- LLM inference: ~2 GB per 1B parameters (FP16)
- LLM fine-tuning: ~16 GB per 1B parameters (with optimizer states)

#### ModernBERT: The 2024 Encoder Evolution

ModernBERT, released in December 2024 by Answer.AI and LightOn, represents a significant modernization of the encoder architecture [2.28]:

**Key Improvements:**
- **8,192 token context** (vs. 512 for original BERT)—enables full-document analysis
- **Up to 400% faster** training and inference
- **80% less memory** than DeBERTaV3
- **Rotary Positional Embeddings (RoPE)** for better position understanding
- **Flash Attention** for efficient computation
- **First encoder with code** in training data

**Clinical Relevance:** Clinical ModernBERT extends this to biomedical applications, trained on MIMIC-IV, PubMed, and medical ontologies—providing a modern encoder for healthcare NLP that can process entire clinical documents [2.25].

#### Decision Framework: Encoder vs. Decoder

| Requirement | Choose Encoder (BERT) | Choose Decoder (LLM) |
|-------------|----------------------|---------------------|
| Task type | Classification, NER, embeddings | Generation, conversation, reasoning |
| Output format | Fixed categories, extracted spans | Free-form text |
| Data availability | Have labeled training data | Limited or no labeled data |
| Compute budget | Limited (consumer GPU) | Moderate to high |
| Latency requirement | Sub-100ms responses | 1-10+ second responses acceptable |
| Interpretability | Need confidence scores | Need explanations |

#### Hybrid Architecture: Best of Both Worlds

Many production systems combine both approaches [2.21]:

1. **BERT for Retrieval**: Use encoder models to create embeddings for semantic search
2. **LLM for Generation**: Use decoder models to generate responses grounded in retrieved content
3. **Example RAG Pipeline**:
   - ClinicalBERT embeds clinical documents → Vector database stores embeddings
   - User query embedded with same model → Retrieve relevant documents
   - Llama/Mistral generates response using retrieved context

This hybrid approach leverages BERT's superior embedding quality with LLM's generation capabilities, while keeping sensitive data processing local.

### 2.4 Understanding the Integration Stack

To build effective AI applications, it's crucial to understand the three distinct approaches to connecting LLMs with external systems [2.8, 2.9]:

| Aspect | Direct API Calls | Orchestration (LangChain) | Protocol (MCP) |
|--------|------------------|---------------------------|----------------|
| Layer | Application | Orchestration | Integration |
| Coupling | Tightly coupled | Framework-dependent | Loosely coupled |
| Key Features | Custom code per service, full control | Multi-step reasoning, state management, tool chaining | Universal interface, runtime discovery, plug-and-play |
| Best For | Simple apps, prototypes | Complex workflows | Enterprise tool sharing |

**How They Work Together:**
MCP is not a replacement for orchestration frameworks—it's a complement [2.8]. LangChain has built-in MCP support, allowing agents to dynamically discover and use MCP-compatible tools while still benefiting from LangChain's reasoning and state management capabilities.

### 2.5 Retrieval-Augmented Generation (RAG)

RAG represents one of the most important architectural patterns for healthcare AI applications [2.1]. It addresses a fundamental limitation of LLMs—their knowledge is frozen at training time and may not include institution-specific protocols, recent research, or patient-specific information.

**The RAG Workflow:**

| Step | Stage | Description |
|------|-------|-------------|
| 1 | Query | User submits a question or request |
| 2 | Retrieve | System searches knowledge base (vector DB, documents) for relevant content |
| 3 | Augment | Retrieved context is added to the prompt sent to the LLM |
| 4 | Generate | LLM produces response grounded in the retrieved information |

*RAG grounds LLM responses in authoritative sources, reducing hallucinations and enabling up-to-date information retrieval.*

**Benefits for Healthcare:**
- Grounds responses in authoritative sources (clinical guidelines, research)
- Enables use of institution-specific protocols
- Reduces hallucinations by providing factual anchors
- Allows for easy updates without model retraining
- Supports citations and source attribution

### 2.6 Embeddings: The Foundation of Semantic Search

Embeddings are the mathematical representations that make modern AI systems possible [2.16, 2.17]. They convert real-world objects—text, images, audio—into numerical vectors that capture meaning and relationships.

**How Embeddings Work:**
1. A neural network processes input data (e.g., a sentence)
2. The network's hidden layers transform this into a multi-dimensional vector
3. Similar items end up as vectors that are close together in the embedding space
4. Distance between vectors (often measured by cosine similarity) represents semantic similarity

**Embedding Space Clustering:**

| Semantic Cluster | Terms in Cluster | Why They Cluster |
|-----------------|------------------|------------------|
| Medical Terms | diagnosis, treatment, symptoms, patient | General healthcare vocabulary; used together in clinical contexts |
| Cardiology Terms | heart, cardiac, coronary, cardiovascular | Semantically similar; often interchangeable in medical texts |
| Facility Terms | hospital, clinic, facility | All refer to healthcare locations |

*Key Insight: In embedding space, semantically similar words cluster together. "Heart" and "cardiac" are close because they appear in similar contexts, even though they're spelled differently. This enables semantic search—finding content by meaning rather than exact keyword matching.*

### 2.7 Vector Databases vs. Graph Databases

The choice between vector and graph databases has important implications for AI system design [2.15].

| Aspect | Vector Database | Graph Database |
|--------|-----------------|----------------|
| Stores | High-dimensional vectors | Nodes and edges (relationships) |
| Search Method | Nearest neighbor similarity | Graph traversal, pattern matching |
| Strengths | Fast similarity search; handles unstructured data; ML pipeline integration | Full transparency; complex relationships; easy error tracing |
| Limitations | "Black box" nature; hard to trace errors | Complex data modeling; scale challenges |
| Examples | Pinecone, Weaviate, Milvus, ChromaDB | Neo4j, FalkorDB, Amazon Neptune |
| Best For | Semantic search, RAG retrieval | Knowledge graphs, relationship queries |

*Emerging Trend: Hybrid architectures ("GraphRAG") combine both approaches—semantic search capabilities with relationship awareness and explainability.*

---

## Section 3: Healthcare AI Deployments and Use Cases

### 3.1 Python Libraries for Healthcare AI

Python has become the lingua franca of healthcare AI development [3.4]. Several specialized libraries have emerged to address the unique challenges of medical machine learning.

| Library | Purpose | Key Features |
|---------|---------|--------------|
| PyHealth | Healthcare ML toolkit | MIMIC support, 10-line pipelines, drug recommendation, mortality prediction |
| MONAI | Medical imaging | PyTorch-based, NVIDIA-backed, clinical-grade deployment |
| TensorFlow/PyTorch | Deep learning | Core frameworks for model development |
| Biopython | Bioinformatics | Genomics analysis, NGS data handling |
| Scikit-learn | Traditional ML | Interpretable algorithms, preprocessing |

### 3.2 Large-Scale Healthcare AI Deployments

#### Microsoft/Nuance DAX Copilot and Epic Integration [3.1]

The most significant enterprise healthcare AI deployment combines Microsoft's Nuance DAX Copilot with Epic's EHR system—creating an ambient AI documentation solution used across hundreds of health systems.

**DAX Copilot Clinical Trial Results (Atrium Health Study, 2024):**

| Metric | DAX Copilot Users | Control Group |
|--------|-------------------|---------------|
| After-Hours EHR Time Reduction | 47% | 14% |
| Documentation Time Reduction | 43% | 18% |
| EHR Frustration Reduction | 44% | 15% |

*DAX Copilot users showed 3x greater improvement across all measures compared to control group.*

**Deployment Scale [3.1]:**
- 150+ health systems deploying at scale
- 77% of U.S. hospitals using Nuance solutions
- 305 million patients with Epic records
- Key partners: Stanford Medicine, Providence, Cleveland Clinic, Duke Health, Johns Hopkins

#### Startup Disruption in Healthcare AI

Despite Microsoft's strong position, startups have captured significant market share. Research shows 85% of all generative AI spend in healthcare currently flows to startups rather than incumbents.

**Notable Healthcare AI Startups:**
- **Abridge**: Clinical documentation AI, capturing ~70% of new ambient AI market alongside Ambience
- **Ambience Healthcare**: Ambient AI platform for clinical documentation
- **Tempus**: AI-driven precision medicine platform
- **Viz.ai**: AI-powered stroke detection and care coordination

### 3.3 Healthcare AI Market Statistics (2024-2025) [3.2]

**Healthcare AI Growth Metrics:**

| Metric | 2024 | 2025 | Growth |
|--------|------|------|--------|
| AI Spending (billions USD) | $0.5B | $1.4B | 2.8x |
| Organization Adoption (%) | 3% | 22% | 7.3x |
| Health System Adoption (%) | 4% | 27% | 6.8x |

*Healthcare AI adoption accelerated dramatically from 2024 to 2025, with spending nearly tripling and adoption rates increasing 6-7x across organizations.*

### 3.4 Case Study: IBM Watson for Oncology—A $4 Billion Lesson [3.3]

IBM Watson for Oncology represents perhaps the most spectacular failure in medical AI history, offering crucial lessons for the field.

**IBM Watson for Oncology Timeline:**

| Phase | Stage | Details |
|-------|-------|---------|
| 1 | Investment | >$5 billion in acquisitions and development |
| 2 | Development | Trained on synthetic (hypothetical) cases, not real patient data |
| 3 | Failure | 12-96% accuracy (highly variable); some recommendations called "dangerous" |
| 4 | Sale (2022) | Sold for ~$1 billion |
| | **NET LOSS** | **~$4 Billion** |

#### What Went Wrong

1. **Synthetic Training Data**: Watson was trained on hypothetical cases created by MSK physicians rather than real patient data, creating an AI that couldn't handle the messy reality of clinical practice.

2. **Variable Performance**: Concordance with expert oncologists ranged from 12% (gastric cancer in China) to 96% (only at sites using similar guidelines).

3. **Dangerous Recommendations**: Memorial Sloan Kettering acknowledged some recommendations were "useless and dangerous."

4. **Inability to Adapt**: The system could not incorporate breakthrough treatments or adapt to local practice variations.

#### Lessons Learned

1. **Real-world data is essential**: AI systems must be trained and validated on actual patient data, not hypothetical scenarios.
2. **External validation is critical**: Performance must be verified across diverse institutions, populations, and clinical settings.
3. **Integration matters**: AI must fit into existing clinical workflows rather than requiring workflow changes.
4. **Continuous learning required**: Medical AI must be able to incorporate new treatments and guidelines.
5. **Start narrow**: Focus on well-defined problems with clear evaluation criteria before expanding scope.

### 3.5 Other Notable Healthcare AI Challenges

#### Epic's Sepsis Prediction Model

Epic's sepsis prediction model, deployed across many hospitals, demonstrated the challenges of AI alerts in clinical settings:
- Generated alerts for 18% of all hospitalized patients
- Missed 67% of actual sepsis cases
- External validation showed AUC of 0.63 vs. advertised 0.73-0.83
- Only identified 33% of sepsis patients while generating numerous false alarms

#### Google's Diabetic Retinopathy System in Thailand

Google's Verily Health Sciences conducted field trials of their diabetic retinopathy detection system in Thailand:
- 21% of images rejected as unsuitable
- Poor lighting conditions and lower-resolution cameras than training data
- Highlighted the gap between laboratory performance and real-world deployment

#### Systemic Challenges

**Data Quality**: Gartner estimates that 85% of AI models fail due to poor data quality. Healthcare data presents unique challenges—duplicate records, inconsistent coding, missing values, and documentation variability.

**Bias**: Gender bias pervades medical AI systems. A University College London study found liver disease screening algorithms were twice as likely to miss the condition in women compared to men.

---

## Section 4: AI in Social Services and Foster Care

The child welfare and social services sector is experiencing rapid AI adoption, with major technology companies and specialized vendors deploying solutions across state and federal agencies [4.1, 4.3, 4.5].

### 4.1 Industry Landscape

| Consultancies | Specialized Vendors | Cloud Platforms |
|---------------|--------------------|--------------------|
| Deloitte (GovConnect) | Binti (46% of children in care) | Salesforce (Agentforce) |
| Accenture (ACIS) | Northwoods (Traverse) | Microsoft (Azure) |
| CGI (Transcend) | RedMane (mCase) | AWS (HHS Cloud) |
| Infosys (CCWIS) | Merative (Cúram) | Oracle (CX Public) |

### 4.2 Major Consultancy Implementations

#### Deloitte — GovConnect Platform [4.1, 4.2]
Deloitte's GovConnect is a collection of low-code/no-code solutions for child welfare, child care licensing, housing assistance, and foster care. Using GenAI, GovConnect unlocks back-end efficiencies to improve timely delivery of family services.

**Key Deployments:**
- Delaware FOCUS—nation's first cloud-based CRM for child welfare
- Washington State—mobile apps for caseworkers and foster families
- Illinois DCFS—Ally IL tool for foster care relationship management

#### Accenture — Case Insight Solution (ACIS) [4.3, 4.4]
ACIS is a Salesforce-based, CCWIS-enabled case management system with GenAI innovation for streamlined intake, holistic case views, and optimized caseworker decision-making.

**Features:** Virtual reality training (AVEnueS), no-code workflow updates, integrated eSignature, and paperless processes.

#### CGI — Transcend Platform [4.5]
CGI Transcend is a cloud-native platform with 25+ years of child welfare experience, serving 16,000+ caseworkers across multiple states.

**Notable Projects:** Alaska ORCA system (450 social workers, 33 locations), Wisconsin SACWIS (award-winning implementation).

#### Infosys — CCWIS Solution [4.18, 4.19]
Infosys CCWIS uses automated data-science technologies and pre-built AI models for predictive insights and identification of high-risk children.

**Partnership:** Texas DFPS—modernizing the statewide system serving 12 million Texans.

### 4.3 Specialized Child Welfare Vendors

#### Binti — AI-Powered Foster Care Platform [4.6, 4.7]

Binti is the first workflow software in child welfare, now serving **46% of children in care nationwide** across 550+ agencies in 36 states.

**Binti AI Platform Results:**

| Metric | Improvement |
|--------|-------------|
| Administrative Time Reduction | 80% |
| Licensing Time Reduction | 75% |
| Increase in Families Licensed (Year 1) | 80% |

**AI Features:**
- Automatic transcription of family meetings and form population
- Natural language chat for interacting with case files
- Built-in translation to support families in multiple languages
- 80% reduction in caseworker administrative time

#### Northwoods — Traverse Platform [4.8]
Traverse is cloud-based, AI-powered software for health and human services, used by nearly 45,000 caseworkers nationwide. It automatically analyzes case content to surface key insights.

**Benefits:** 2 hours saved per caseworker daily, $130,000 annual savings per 200-child agency by reducing length of stay.

#### RedMane — mCase Platform [4.9]
mCase is designed by experienced social workers, providing AI-powered intake tools and mobile case management. The February 2025 white paper discusses AI's role in child welfare intake management.

**Deployments:** Georgia DFCS (3-month implementation), Florida APD incident management.

#### Merative (IBM Cúram) [4.10]
Cúram has 25 years of experience, serving 187 million citizens annually across 12 countries in 14 languages.

**Programs Supported:** Foster care, child welfare, Medicaid, SNAP, TANF, CHIP, LIHEAP.

### 4.4 Cloud Platform Solutions

#### Salesforce — Agentforce for Child Welfare [4.11, 4.12]
Salesforce is piloting Agentforce for caseworkers, which processes and summarizes historical data (health, financial, education) and analyzes information against reports and policies.

**Results:** Indiana CCWIS—nation's first FedRAMP-authorized child welfare CRM. Noble Child platform reduced foster home licensing from 13 months to 6 months.

#### Microsoft Azure [4.13, 4.14]
Microsoft offers ECAP (Every Child A Priority) on Azure Government cloud, using algorithms to match children with families based on medical needs, behaviors, preferences, and qualifications.

**Global Scale:** UNICEF Primero platform targets 60 countries by 2025.

#### AWS — Health and Human Services Cloud [4.15]
AWS provides AI/ML services including Amazon Textract and Comprehend for document processing. The Miracle Foundation built a production AI assistant analyzing case files and flagging urgent situations.

**Investment:** $50 billion in AI infrastructure for government agencies; 7,500+ US agencies served.

#### Oracle — CX for Public Sector [4.16]
Oracle provides declarative AI modeling for eligibility determination and case-specific action plans.

**Contract:** $25M HHS Oracle Cloud Services contract awarded.

### 4.5 CCWIS Compliance Context

The Comprehensive Child Welfare Information System (CCWIS) final rule (June 2016) guides technology use in child welfare. As of May 2023, **46 states plus DC and Puerto Rico** have adopted CCWIS.

**AI Applications in Child Welfare:**

| Application | Description |
|-------------|-------------|
| Automated Data Entry | AI extracts information from documents and forms |
| Predictive Analytics | Risk scoring to identify high-risk children |
| Natural Language Processing | Case note summarization and search |
| Foster Care Matching | AI matches children with appropriate families |
| Translation Services | Real-time translation for multilingual families |

### 4.6 Cautions and Concerns

**Bias Risks:** Historic decision-making in child welfare has been affected by racial and socioeconomic biases. Some states have halted AI pilots due to concerns about transparency and discrimination.

**Best Practice:** AI should enhance caseworker insight rather than automate decision-making. As RedMane notes: "AI can analyze patterns and surface insights, but it cannot understand lived experience, family dynamics, or context the way a skilled practitioner can."

---

## Section 5: How Large Language Models Work: Knowledge Without Databases

*"When I asked LLAMA locally when the Cincinnati Reds won the World Series, it answered correctly—without internet access. How?"*

This section explains how LLMs store and retrieve factual knowledge without traditional databases.

### 5.1 The Fundamental Insight

LLMs don't remember text—they learn patterns [5.1, 5.4]. Inside an LLM, there's no text, no files, no database tables—**just billions of numbers called parameters**. These parameters encode statistical patterns learned during training.

**Database vs. LLM Knowledge Storage:**

| Aspect | Traditional Database | LLM Parameters |
|--------|---------------------|----------------|
| Example | `{"team": "Reds", "years": [1975, 1976]}` | `0.0234, -0.8921, 0.4512, ...` (7 billion numbers) |
| Storage | Explicit storage of facts | Patterns encoded in weights |
| Retrieval | Direct lookup via query | Pattern completion (probability) |

*Key insight: LLMs do NOT store facts like a database. There is no "Cincinnati Reds" entry inside the model—only billions of numerical weights that collectively encode statistical patterns from training data.*

### 5.2 What Are Parameters?

A parameter is a numerical value (typically a 16-bit or 32-bit floating-point number) that the model learns during training [5.2, 5.3]. There are three main types:

**1. Embeddings:** Mathematical representations of words/tokens. Each word in the vocabulary gets a vector (e.g., 768 dimensions) that captures its meaning relative to all other words.

**2. Weights:** Numerical values representing the importance of connections between neurons. Higher weights mean stronger influence on the output.

**3. Biases:** Values that adjust activation thresholds, allowing neurons to fire even when inputs are low.

**Scale of LLM Parameters:**

| Model | Parameters | Scale |
|-------|------------|-------|
| GPT-2 Small | 124 million | Baseline |
| LLaMA 7B | 7 billion | 56x GPT-2 |
| LLaMA 70B | 70 billion | 565x GPT-2 |
| GPT-4 | ~1.8 trillion | 14,500x GPT-2 |

*Each parameter is a floating-point number storing a small piece of learned pattern. More parameters generally enable more knowledge and capability.*

### 5.3 The Cincinnati Reds Example

When you ask "When did the Cincinnati Reds win the World Series?", here's what happens:

| Step | Stage | What Happens |
|------|-------|--------------|
| 1 | Tokenization | Input text split into tokens: "Cincinnati" → [4521], "Reds" → [8734] |
| 2 | Embedding | Each token converted to a 768+ dimension vector |
| 3 | Processing | Vectors pass through 100+ transformer layers (matrix multiplications) |
| 4 | Output | Model generates response token-by-token: "1975, 1976..." |

*The model doesn't "look up" the answer. It generates "1975" because that token has the highest probability given the learned patterns from training.*

**Key Point:** The model doesn't "look up" the answer. During training, it saw millions of texts mentioning the Cincinnati Reds and World Series. The statistical patterns of which words follow "Cincinnati Reds won the World Series in..." became encoded in the weights. The model generates "1975" because that token has the highest probability given the learned patterns.

### 5.4 Knowledge Encoded in Weights [5.6]

**Weight Matrix vs. Relational Database:**

| Aspect | LLM Weight Matrix | Traditional Database |
|--------|-------------------|---------------------|
| Structure | Grid of floating-point numbers connecting input to output neurons | Rows and columns with explicit fields |
| Query | "Cincinnati Reds World Series" activates patterns across millions of weights | `SELECT year WHERE team='Reds'` returns specific rows |
| Fact Location | Distributed—no single "fact" location; knowledge spread across weights | Explicit—facts stored in specific records |
| Modification | Requires retraining entire model | Simple UPDATE statement |

### 5.5 Why This Matters

**LLM Knowledge vs. Traditional Storage:**

| Characteristic | LLM (Parameters) | Database/JSON |
|----------------|------------------|---------------|
| Storage format | Billions of floating-point numbers | Structured tables or key-value pairs |
| How facts are stored | Distributed across many weights | Explicit records |
| Retrieval method | Pattern completion (probability) | Direct lookup (query) |
| Updating facts | Requires retraining | Simple INSERT/UPDATE |
| Error correction | Very difficult | Easy to fix specific records |
| Explainability | "Black box" | Fully transparent |

### 5.6 The Training Process [5.5]

**How Knowledge Gets Encoded During Training:**

| Step | Stage | Example |
|------|-------|---------|
| 1 | Training Data | "The Cincinnati Reds won the 1975 World..." (billions of documents from the internet) |
| 2 | Learning | Model predicts next token ("Series"); adjusts weights when correct/incorrect |
| 3 | Encoded Knowledge | "Reds + 1975 + won + World Series" pattern strengthened in weights |

*After seeing similar phrases billions of times, statistical associations become strong enough for reliable answer generation.*

**The model saw the phrase "Cincinnati Reds won the World Series in 1975" (and similar) many times during training. Each time, the weights connecting "Cincinnati," "Reds," "World Series," and "1975" were slightly strengthened. After billions of examples, these statistical associations become strong enough that the model can reliably produce the correct answer.**

### 5.7 Limitations of Parametric Knowledge [5.4, 5.5]

- **Knowledge Cutoff:** LLMs only know what was in their training data. Events after the cutoff date are unknown.
- **No Real-Time Updates:** Unlike a database, you can't simply update a fact—retraining is required.
- **Confident Errors:** If training data contained errors, the model may confidently produce wrong answers.
- **"Hallucinations":** The model generates plausible-sounding but incorrect information when patterns don't match reality.

**This is why RAG (Section 2.4) is so important**—it grounds LLM responses in authoritative, up-to-date external sources rather than relying solely on parametric knowledge.

---

## Conclusion

Artificial intelligence in healthcare and social services represents both tremendous opportunity and significant risk. The technology landscape has evolved from traditional machine learning suited for structured data to generative AI capable of understanding and producing natural language.

**Key Takeaways:**

1. **Different tools for different problems**: Traditional ML and generative AI serve complementary purposes—choose based on data type, interpretability needs, and use case.

2. **Infrastructure has matured**: Frameworks like LangGraph enable production-grade AI systems; hybrid vector-graph architectures address needs for both search and explainability.

3. **Real promise exists**: Ambient documentation AI demonstrates meaningful reductions in clinician burnout; Binti's platform serves 46% of children in foster care.

4. **LLMs are pattern machines**: They store knowledge in billions of parameters, not databases—enabling remarkable capabilities but also creating challenges for updates and error correction.

5. **Failures teach critical lessons**: The IBM Watson case and child welfare bias concerns remind us that careful validation and human oversight remain essential.

**Pillars of Successful AI Implementation:**

| Pillar | Description |
|--------|-------------|
| Right Tool | Choose ML vs. Generative AI based on use case, data type, and interpretability needs |
| Integration | Fit AI into existing clinical and caseworker workflows—don't force workflow changes |
| Monitoring | Continuous evaluation, performance tracking, and regular updates |
| Humility | Acknowledge current limitations; maintain human oversight |

*Foundation: Real-World Data & Rigorous Validation*

The future of AI in healthcare and social services lies not in replacing human judgment but in augmenting it—providing clinicians and caseworkers with better information, reducing administrative burden, and enabling more time for the human relationships at the heart of both fields.

---

## References

### Section 1: Machine Learning vs. Generative AI

- [1.1] Lamatic AI. "ML VS LLM Decision Matrix Explained." https://blog.lamatic.ai/guides/ml-vs-llm/
- [1.2] Revelo. "8 Differences Between Machine Learning vs. Generative AI." https://www.revelo.com/blog/generative-ai-vs-machine-learning
- [1.3] Oracle. "AI vs. Gen AI vs. ML: Key Differences." https://www.oracle.com/artificial-intelligence/ai-vs-gen-ai-vs-ml/
- [1.4] IBM. "AI vs. Machine Learning vs. Deep Learning vs. Neural Networks." https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks
- [1.5] MIT Sloan. "Machine learning and generative AI: What are they good for in 2025?" https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-and-generative-ai-what-are-they-good-for

### Section 2: LLM Methods and Infrastructure

- [2.1] Xenoss. "LangChain vs LangGraph vs LlamaIndex." https://xenoss.io/blog/langchain-langgraph-llamaindex-llm-frameworks
- [2.2] LangChain. "LangGraph." https://www.langchain.com/langgraph
- [2.3] Anthropic. "Claude Code: Best practices for agentic coding." https://www.anthropic.com/engineering/claude-code-best-practices
- [2.4] Anthropic. "Introducing the Model Context Protocol." November 2024. https://www.anthropic.com/news/model-context-protocol
- [2.5] Model Context Protocol. "Specification." https://modelcontextprotocol.io/specification/2025-11-25
- [2.6] The New Stack. "Why the Model Context Protocol Won." https://thenewstack.io/why-the-model-context-protocol-won/
- [2.7] DEV Community. "One Year of Model Context Protocol." https://dev.to/ajeetraina/one-year-of-model-context-protocol-from-experiment-to-industry-standard-5hj8
- [2.8] Medium (Jalaj Agrawal). "LangChain vs. MCP—How They Work." https://medium.com/@jalajagr/langchain-vs-mcp-how-they-work-when-to-use-them-and-why-they-matter-171c5b6fab1c
- [2.9] Glama. "Comparing MCP vs LangChain/ReAct for Chatbots." https://glama.ai/blog/2025-09-02-comparing-mcp-vs-lang-chainre-act-for-chatbots
- [2.10] Medium (Rost Glukhov). "Local LLM Hosting: Complete 2025 Guide." https://medium.com/@rosgluk/local-llm-hosting-complete-2025-guide-ollama-vllm-localai-jan-lm-studio-more-f98136ce7e4a
- [2.11] Digital Applied. "Local LLM Deployment: Privacy-First AI Complete Guide." https://www.digitalapplied.com/blog/local-llm-deployment-privacy-guide-2025
- [2.12] DataCamp. "Pros and Cons of Using LLMs in Cloud vs. Running Locally." https://www.datacamp.com/blog/the-pros-and-cons-of-using-llm-in-the-cloud-versus-running-llm-locally
- [2.13] AI Multiple Research. "Cloud LLM vs Local LLMs: Real-Life Examples." https://research.aimultiple.com/cloud-llm/
- [2.14] House of FOSS. "Ollama vs llama.cpp vs vLLM: Local LLM Deployment in 2025." https://www.houseoffoss.com/post/ollama-vs-llama-cpp-vs-vllm-local-llm-deployment-in-2025
- [2.15] FalkorDB. "Knowledge graph vs vector database." https://www.falkordb.com/blog/knowledge-graph-vs-vector-database/
- [2.16] AWS. "What is Embedding?" https://aws.amazon.com/what-is/embeddings-in-machine-learning/
- [2.17] IBM. "What is Embedding?" https://www.ibm.com/think/topics/embedding
- [2.18] Sebastian Raschka. "Understanding Encoder And Decoder LLMs." https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder
- [2.19] Hugging Face. "Transformer Architectures - LLM Course." https://huggingface.co/learn/llm-course/chapter1/6
- [2.20] Milvus. "What is the difference between BERT and GPT?" https://milvus.io/ai-quick-reference/what-is-the-difference-between-bert-and-gpt
- [2.21] DEV Community. "GPT and BERT: A Comparison of Transformer Architectures." https://dev.to/meetkern/gpt-and-bert-a-comparison-of-transformer-architectures-2k46
- [2.22] PMC/NIH. "Fine-Tuned BERT vs ChatGPT for Medical Specialty Recommendations." https://pmc.ncbi.nlm.nih.gov/articles/PMC11530716/
- [2.23] Hugging Face. "Bio_ClinicalBERT Model." https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT
- [2.24] Microsoft Research. "Domain-specific language model pretraining for biomedical NLP." https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing/
- [2.25] arXiv. "Clinical ModernBERT: An efficient and long context encoder for biomedical text." https://arxiv.org/html/2504.03964v1
- [2.26] Runpod. "The Complete Guide to GPU Requirements for LLM Fine-Tuning." https://www.runpod.io/blog/llm-fine-tuning-gpu-guide
- [2.27] Chris McCormick. "GPU Benchmarks for Fine-Tuning BERT." https://mccormickml.com/2020/07/21/gpu-benchmarks-for-fine-tuning-bert/
- [2.28] Hugging Face Blog. "Finally, a Replacement for BERT: Introducing ModernBERT." https://huggingface.co/blog/modernbert

### Section 3: Healthcare AI Deployments

- [3.1] Nuance. "DAX Copilot Embedded in Epic." January 2024. https://news.nuance.com/2024-01-18-Nuance-Announces-General-Availability-of-DAX-Copilot-Embedded-in-Epic
- [3.2] Menlo Ventures. "2025: The State of AI in Healthcare." https://menlovc.com/perspective/2025-the-state-of-ai-in-healthcare/
- [3.3] Henrico Dolfing. "IBM Watson for Oncology Failure." December 2024. https://www.henricodolfing.com/2024/12/case-study-ibm-watson-for-oncology-failure.html
- [3.4] PyHealth Documentation. https://pyhealth.readthedocs.io/

### Section 4: AI in Social Services and Foster Care

- [4.1] Deloitte. "State Health and Human Services." https://www2.deloitte.com/us/en/pages/public-sector/solutions/health-and-human-services.html
- [4.2] Deloitte. "GenAI for HHS Solutions." https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloitte-enhances-its-state-and-local-government-health-and-human-services-solutions-with-trustworthy-generative-ai.html
- [4.3] Accenture. "Child Welfare Services." https://www.accenture.com/us-en/services/public-service/health-human-services-child-welfare
- [4.4] Accenture. "Case Insight Solution (ACIS)." https://www.accenture.com/in-en/industries/public-service/health-and-human-service-case-insight-solution
- [4.5] CGI. "Child Welfare." https://www.cgi.com/us/en-us/state-local-government/hhs/child-welfare
- [4.6] Binti. "Software Built for Child Welfare." https://binti.com/
- [4.7] GovCIO Outlook. "Binti: Top Child Welfare Software 2025." https://www.govciooutlook.com/binti
- [4.8] Northwoods. "Traverse Platform." https://www.teamnorthwoods.com/traverse/
- [4.9] RedMane. "AI-Powered Intake Tools White Paper." February 2025. https://www.redmane.com/redmane-releases-new-white-paper-ai/
- [4.10] Merative. "Cúram Child Welfare." https://www.merative.com/curam/child-welfare
- [4.11] Salesforce. "Agentforce for Child Welfare." https://www.salesforce.com/news/stories/agentic-ai-revolutionizes-child-welfare/
- [4.12] Salesforce. "Indiana Department of Child Services." https://www.salesforce.com/customer-success-stories/state-of-indiana-department/
- [4.13] Microsoft. "The Contingent Case Study." https://www.microsoft.com/en/customers/story/1625541988925138544-thecontingent-microsoftcloudfornonprofit-unitedstates
- [4.14] Microsoft. "UNICEF Primero Platform." https://blogs.microsoft.com/conexiones/2020/12/11/unicef-and-microsoft-scale-azure-based-platform-primero-to-empower-social-workers-and-help-more-children/
- [4.15] AWS. "Cloud for Health and Human Services." https://aws.amazon.com/stateandlocal/health-and-human-services/
- [4.16] Oracle. "Child Welfare CX." https://www.oracle.com/government/constituent-services/child-welfare/
- [4.17] CMA Consulting. "Child Welfare Case Management." https://cma.com/services/case-management-platforms/child-welfare
- [4.18] Infosys. "CCWIS Solution." https://www.infosyspublicservices.com/health-human-services-enterprise/child-welfare-information-solution.html
- [4.19] Infosys. "Role of AI in CCWIS." https://www.infosyspublicservices.com/insights/blogs/ai-role-child-welfare-information-system.html

### Section 5: How LLMs Work

- [5.1] Microsoft. "Where Does an LLM Keep All That Knowledge?" https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/where-does-an-llm-keep-all-that-knowledge-a-peek-into-the-physical-side-of-ai/4410287
- [5.2] MIT Technology Review. "LLMs contain a LOT of parameters. But what's a parameter?" January 2026. https://www.technologyreview.com/2026/01/07/1130795/what-even-is-a-parameter/
- [5.3] IBM. "What Are LLM Parameters?" https://www.ibm.com/think/topics/llm-parameters
- [5.4] Medium (Amarjit Singh). "LLMs Don't Store Training Data—Here's What is Stored Inside Them." https://medium.com/@amarjit86255/llms-dont-store-training-data-here-s-what-is-stored-inside-them-04c2c70c1daa
- [5.5] Future of Privacy Forum. "Nature of Data in Pre-Trained Large Language Models." https://fpf.org/blog/nature-of-data-in-pre-trained-large-language-models/
- [5.6] The Thought Process. "How Does LLMs Store Knowledge? A Deep Dive Into Feature Superposition." https://thethoughtprocess.xyz/en/how-does-llms-store-knowledge-a-deep-dive-into-feature-superposition/
- [5.7] Transformer Explainer (Georgia Tech). Interactive visualization tool. https://poloclub.github.io/transformer-explainer/

---

*Document prepared January 2026*
*For educational and presentation purposes*
