# CFSR Item 3 Prompt: Theme Extraction with Semantic Relationship Mapping

## Version 2 — With Causal/Relational Graph Layer

---

## The Prompt

```
You are an expert analyst reviewing Child and Family Services Review (CFSR) case
narratives for quality improvement and systems analysis. You are analyzing Item 3:
"Did the agency make concerted efforts to assess and address the risk and safety
concerns relating to the child(ren) in their own homes or while in foster care?"

You will perform TWO extraction tasks:
1. Extract structured themes from the narrative
2. Map semantic relationships and directional causality between entities in the narrative

---

## TASK 1: THEME EXTRACTION

Read the case narrative and identify each distinct issue or observation. For each, extract:

**theme** — Classify into one of these categories:
- "initial_safety_assessment" — timeliness and quality of initial safety evaluation
- "ongoing_safety_assessment" — continuing evaluation throughout case life
- "safety_planning" — development, adequacy, and updating of safety plans
- "risk_assessment" — formal risk assessment tool usage, fidelity, and quality
- "safety_monitoring" — follow-up contacts, visits, verification of safety plan compliance
- "caregiver_protective_capacity" — assessment of caregiver ability and willingness to protect
- "hazard_identification" — identification of specific dangers in home or placement
- "placement_safety" — safety assessment and monitoring in foster care settings
- "domestic_violence" — DV-specific safety concerns, screening, and response
- "substance_abuse" — substance use-related safety concerns, testing, treatment engagement
- "mental_health" — mental health-related safety concerns for any party
- "supervision" — adequacy of child supervision by caregivers
- "documentation" — quality, completeness, and timeliness of safety-related case documentation
- "communication" — information sharing between workers, providers, courts, or families
- "service_provision" — referrals, service delivery, and follow-through
- "other" — if none above fit, provide a brief descriptor in parentheses

**finding** — "strength", "concern", or "neutral"

**excerpt** — A brief paraphrase (under 50 words) capturing the specific observation.
Do not copy narrative text verbatim; summarize the observation in your own words.

**actor** — The primary subject:
"agency", "caseworker", "supervisor", "caregiver", "foster_parent",
"provider", "court", "child", or "other"

**timeframe** — When the observation applies:
"initial" (first 30 days), "ongoing", "at_removal", "at_placement",
"current", or "unspecified"

---

## TASK 2: SEMANTIC RELATIONSHIP EXTRACTION

Identify meaningful relationships between entities, conditions, actions, and outcomes
described in the narrative. These are the real-world connections between things —
how one situation leads to another, how an action addresses a problem, or how
conditions co-occur.

**Semantic objects** are the concrete nouns, conditions, events, actions, or states
mentioned in the narrative. Extract them as short, specific noun phrases.
Good: "father's methamphetamine use", "missed home visits", "child's school absences"
Bad: "problems", "issues", "concerns" (too vague)

For each relationship, extract:

**source_object** — The semantic object that initiates, causes, or precedes
(a short noun phrase, 2-8 words)

**relationship_type** — One of:
- "causes" — A directly produces B
- "contributes_to" — A is a factor in B but not sole cause
- "leads_to" — A results in B over time or through a chain
- "exacerbates" — A makes existing B worse
- "mitigates" — A reduces the severity or likelihood of B
- "prevents" — A blocks B from occurring
- "triggers" — A initiates or activates B
- "co_occurs_with" — A and B appear together; causation unclear
- "undermines" — A weakens or counteracts B
- "addresses" — A is a response or intervention targeting B
- "reveals" — A exposes or makes B visible
- "enables" — A creates conditions for B to happen

**target_object** — The semantic object that is affected, produced, or follows
(a short noun phrase, 2-8 words)

**related_themes** — List of 1-2 theme categories (from Task 1) this relationship
connects to

**confidence** — "high", "medium", or "low" based on how explicitly the narrative
states this connection vs. how much you are inferring

**directionality** — "explicit" if the narrative directly states the connection,
"inferred" if you are reasoning about the connection based on context

---

## OUTPUT FORMAT

Return ONLY valid JSON with no additional text, markdown formatting, or code fences.
The response must contain exactly two top-level keys: "theme_extraction" and "relationship_map".

{
  "theme_extraction": {
    "case_summary": "<1-2 sentence summary of the safety situation>",
    "item_rating": "<strength|area_needing_improvement|not_applicable>",
    "themes": [
      {
        "theme_id": "T1",
        "theme": "<category>",
        "finding": "<strength|concern|neutral>",
        "excerpt": "<paraphrased observation under 50 words>",
        "actor": "<who>",
        "timeframe": "<when>"
      }
    ],
    "primary_concerns": ["<list main safety issues>"],
    "primary_strengths": ["<list main strengths>"]
  },
  "relationship_map": {
    "semantic_objects": [
      {
        "object_id": "S1",
        "label": "<short noun phrase>",
        "object_type": "<condition|action|event|state|person|service|barrier>",
        "sentiment": "<negative|positive|neutral>"
      }
    ],
    "relationships": [
      {
        "source_object_id": "S1",
        "source_label": "<noun phrase>",
        "relationship_type": "<type>",
        "target_object_id": "S2",
        "target_label": "<noun phrase>",
        "related_themes": ["<theme_id>"],
        "confidence": "<high|medium|low>",
        "directionality": "<explicit|inferred>"
      }
    ]
  }
}

---

## GUIDANCE

- Extract ALL meaningful relationships, not just negative ones. Strengths have
  causal chains too (e.g., "consistent home visits" → addresses → "safety monitoring gaps")
- Keep semantic objects specific and grounded in the narrative. Use the language
  and concepts from the case, not abstract categories.
- A single semantic object can appear in multiple relationships.
- Prefer "contributes_to" over "causes" unless the narrative explicitly states
  direct causation. Child welfare cases are complex; most causation is multifactorial.
- The theme_id references in related_themes should match the theme_id values
  from Task 1, connecting the two extractions.
- If the narrative is very brief or lacks detail, return fewer relationships
  rather than speculating. Set confidence to "low" for any inferred connections.
- Aim for 3-10 relationships per case depending on narrative length and complexity.

---

## EXAMPLE

Given a narrative excerpt like: "The caseworker completed the initial safety
assessment within 24 hours. However, the father's ongoing methamphetamine use
was not reassessed after reunification. The mother reported that the father's
drug use led to job loss, and the family was subsequently evicted. The children
were found unsupervised on two occasions after the eviction when the mother
began working double shifts to cover rent."

The relationship_map would include:

semantic_objects:
- S1: "father's methamphetamine use" (condition, negative)
- S2: "father's job loss" (event, negative)
- S3: "family eviction" (event, negative)
- S4: "mother's double work shifts" (state, neutral)
- S5: "children found unsupervised" (event, negative)
- S6: "lack of ongoing substance abuse reassessment" (action, negative)
- S7: "timely initial safety assessment" (action, positive)

relationships:
- S1 → leads_to → S2 (explicit, high)
- S2 → leads_to → S3 (explicit, high)
- S3 → leads_to → S4 (inferred, medium)
- S4 → leads_to → S5 (inferred, medium)
- S1 → contributes_to → S5 (inferred, medium) — upstream root factor
- S6 → undermines → ongoing safety (explicit, high)
- S7 → addresses → initial safety concerns (explicit, high)

Case Narrative:
```
{narrative}
```
```

---

## Usage in Snowflake Cortex

```sql
-- Set the prompt as a session variable
SET prompt_item3_v2 = $$ <full prompt above> $$;

-- Run extraction
SELECT
    case_id,
    review_period,
    state,
    county,
    AI_COMPLETE(
        'claude-3-7-sonnet',
        REPLACE($prompt_item3_v2, '{narrative}', item3_narrative),
        {'temperature': 0.1, 'max_tokens': 4000}
    ) AS extraction
FROM cfsr_case_reviews
WHERE item_number = 3
  AND item3_narrative IS NOT NULL
  AND LENGTH(item3_narrative) > 50;
```

---

## Parsing the Output

### Themes Table

```sql
CREATE OR REPLACE TABLE cfsr_item3_themes AS
WITH parsed AS (
    SELECT
        case_id, review_period, state, county,
        TRY_PARSE_JSON(extraction) AS j
    FROM cfsr_item3_raw
    WHERE extraction IS NOT NULL
)
SELECT
    case_id, review_period, state, county,
    j:theme_extraction:item_rating::STRING AS item_rating,
    j:theme_extraction:case_summary::STRING AS case_summary,
    t.value:theme_id::STRING AS theme_id,
    t.value:theme::STRING AS theme,
    t.value:finding::STRING AS finding,
    t.value:excerpt::STRING AS excerpt,
    t.value:actor::STRING AS actor,
    t.value:timeframe::STRING AS timeframe
FROM parsed,
LATERAL FLATTEN(input => j:theme_extraction:themes) t;
```

### Semantic Objects Table

```sql
CREATE OR REPLACE TABLE cfsr_item3_semantic_objects AS
WITH parsed AS (
    SELECT
        case_id, review_period, state, county,
        TRY_PARSE_JSON(extraction) AS j
    FROM cfsr_item3_raw
    WHERE extraction IS NOT NULL
)
SELECT
    case_id, review_period, state, county,
    s.value:object_id::STRING AS object_id,
    s.value:label::STRING AS label,
    s.value:object_type::STRING AS object_type,
    s.value:sentiment::STRING AS sentiment
FROM parsed,
LATERAL FLATTEN(input => j:relationship_map:semantic_objects) s;
```

### Relationships Table (Edge List)

```sql
CREATE OR REPLACE TABLE cfsr_item3_relationships AS
WITH parsed AS (
    SELECT
        case_id, review_period, state, county,
        TRY_PARSE_JSON(extraction) AS j
    FROM cfsr_item3_raw
    WHERE extraction IS NOT NULL
)
SELECT
    case_id, review_period, state, county,
    r.value:source_object_id::STRING AS source_id,
    r.value:source_label::STRING AS source_label,
    r.value:relationship_type::STRING AS relationship_type,
    r.value:target_object_id::STRING AS target_id,
    r.value:target_label::STRING AS target_label,
    r.value:confidence::STRING AS confidence,
    r.value:directionality::STRING AS directionality
FROM parsed,
LATERAL FLATTEN(input => j:relationship_map:relationships) r;
```

### Relationship-to-Theme Bridge Table

```sql
CREATE OR REPLACE TABLE cfsr_item3_relationship_themes AS
WITH parsed AS (
    SELECT
        case_id, review_period, state, county,
        TRY_PARSE_JSON(extraction) AS j
    FROM cfsr_item3_raw
    WHERE extraction IS NOT NULL
)
SELECT
    case_id, review_period, state, county,
    r.value:source_label::STRING AS source_label,
    r.value:relationship_type::STRING AS relationship_type,
    r.value:target_label::STRING AS target_label,
    th.value::STRING AS related_theme_id
FROM parsed,
LATERAL FLATTEN(input => j:relationship_map:relationships) r,
LATERAL FLATTEN(input => r.value:related_themes) th;
```

---

## Analysis Queries

### Most Common Causal Chains

```sql
-- What conditions most frequently lead to safety concerns?
SELECT
    source_label,
    relationship_type,
    target_label,
    COUNT(DISTINCT case_id) AS cases,
    ROUND(
        SUM(CASE WHEN confidence = 'high' THEN 1 ELSE 0 END)
        * 100.0 / COUNT(*), 0
    ) AS pct_high_confidence
FROM cfsr_item3_relationships
WHERE relationship_type IN ('causes', 'leads_to', 'contributes_to')
GROUP BY source_label, relationship_type, target_label
HAVING COUNT(DISTINCT case_id) >= 3
ORDER BY cases DESC;
```

### Semantic Objects That Appear as Root Causes Most Often

```sql
-- Which objects most frequently appear as SOURCE in causal relationships?
SELECT
    source_label,
    o.object_type,
    o.sentiment,
    COUNT(DISTINCT r.case_id) AS cases_as_cause,
    LISTAGG(DISTINCT r.relationship_type, ', ')
        WITHIN GROUP (ORDER BY r.relationship_type) AS relationship_types,
    LISTAGG(DISTINCT r.target_label, '; ')
        WITHIN GROUP (ORDER BY r.target_label) AS leads_to
FROM cfsr_item3_relationships r
LEFT JOIN cfsr_item3_semantic_objects o
    ON r.case_id = o.case_id AND r.source_id = o.object_id
WHERE r.relationship_type IN ('causes', 'leads_to', 'contributes_to', 'triggers')
GROUP BY source_label, o.object_type, o.sentiment
ORDER BY cases_as_cause DESC
LIMIT 20;
```

### What Interventions Address What Problems?

```sql
-- Map interventions to the problems they target
SELECT
    source_label AS intervention,
    target_label AS problem_addressed,
    COUNT(DISTINCT case_id) AS cases,
    confidence
FROM cfsr_item3_relationships
WHERE relationship_type IN ('addresses', 'mitigates', 'prevents')
GROUP BY source_label, target_label, confidence
ORDER BY cases DESC;
```

### Cross-Case Pattern: Causal Chains by State

```sql
-- Do different states show different causal patterns?
SELECT
    state,
    source_label,
    relationship_type,
    target_label,
    COUNT(*) AS occurrences
FROM cfsr_item3_relationships
WHERE confidence IN ('high', 'medium')
  AND relationship_type IN ('causes', 'leads_to', 'contributes_to')
GROUP BY state, source_label, relationship_type, target_label
HAVING COUNT(*) >= 2
ORDER BY state, occurrences DESC;
```

### Network Centrality: Which Objects Are Most Connected?

```sql
-- Which semantic objects have the most connections (in or out)?
WITH connections AS (
    SELECT source_label AS label, 'outgoing' AS direction, case_id
    FROM cfsr_item3_relationships
    UNION ALL
    SELECT target_label AS label, 'incoming' AS direction, case_id
    FROM cfsr_item3_relationships
)
SELECT
    label,
    COUNT(*) AS total_connections,
    COUNT(DISTINCT case_id) AS across_cases,
    SUM(CASE WHEN direction = 'outgoing' THEN 1 ELSE 0 END) AS outgoing,
    SUM(CASE WHEN direction = 'incoming' THEN 1 ELSE 0 END) AS incoming,
    ROUND(
        SUM(CASE WHEN direction = 'outgoing' THEN 1 ELSE 0 END)
        * 1.0 / NULLIF(
            SUM(CASE WHEN direction = 'incoming' THEN 1 ELSE 0 END), 0
        ), 2
    ) AS out_in_ratio  -- high ratio = root cause; low ratio = downstream effect
FROM connections
GROUP BY label
HAVING COUNT(*) >= 3
ORDER BY total_connections DESC;
```

---

## Neo4j / Graph Database Ingestion

The edge list format maps directly to graph ingestion:

```cypher
// Load semantic objects as nodes
LOAD CSV WITH HEADERS FROM 'file:///semantic_objects.csv' AS row
MERGE (s:SemanticObject {
    case_id: row.case_id,
    object_id: row.object_id
})
SET s.label = row.label,
    s.object_type = row.object_type,
    s.sentiment = row.sentiment,
    s.state = row.state;

// Load relationships as edges
LOAD CSV WITH HEADERS FROM 'file:///relationships.csv' AS row
MATCH (source:SemanticObject {case_id: row.case_id, object_id: row.source_id})
MATCH (target:SemanticObject {case_id: row.case_id, object_id: row.target_id})
CALL apoc.create.relationship(
    source, toUpper(row.relationship_type), {
        confidence: row.confidence,
        directionality: row.directionality,
        case_id: row.case_id
    }, target
) YIELD rel
RETURN count(rel);

// Query: Find all causal chains originating from substance abuse
MATCH path = (root:SemanticObject)-[:CAUSES|LEADS_TO|CONTRIBUTES_TO*1..5]->(effect)
WHERE root.label CONTAINS 'substance'
RETURN path;
```

---

## Key Improvements Over Version 1

| Aspect | V1 | V2 |
|--------|----|----|
| Output structure | Single flat JSON | Two linked extraction layers |
| Theme references | No cross-referencing | theme_id links themes to relationships |
| Causal reasoning | None | Full directional relationship mapping |
| Confidence tracking | None | Per-relationship confidence + explicit vs. inferred |
| Semantic objects | Only theme categories | Concrete noun phrases from narrative |
| Graph-readiness | Requires transformation | Direct edge list output |
| Object typing | None | condition/action/event/state/person/service/barrier |
| Relationship vocabulary | None | 12 typed relationships covering causation, mitigation, co-occurrence |
| Example included | None | Worked example showing expected reasoning |
| Aggregation potential | Theme counts only | Network analysis, centrality, causal chain mining |
